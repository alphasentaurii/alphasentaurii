I"ì	<p>This is a <code class="highlighter-rouge">supervised machine learning feature classification project</code> that uses <code class="highlighter-rouge">Decision Trees and XGBoost</code> to <code class="highlighter-rouge">predict and classify signals as either a pulsar or radio frequency interference (noise)</code>.</p>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_93_1.png" /></div>

<h2 id="htru2">HTRU2</h2>

<p>HTRU2 is a data set which describes <strong>a sample of pulsar candidates collected during the High Time Resolution Universe Survey.</strong></p>

<h2 id="pulsars">Pulsars</h2>

<p>Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter.</p>

<h2 id="what-happens-when-they-rotate">What happens when they rotate?</h2>

<p>Glad you asked. As pulsars rotate, their emission beams sweep across the sky which produces a detectable pattern of broadband radio emission when crossing our line of sight. As pulsars rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.</p>

<h2 id="so-how-do-we-detect-pulsars">So how do we detect pulsars?</h2>

<p>Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation. Detection of a potential signal is known as a â€˜candidateâ€™, which is averaged over many rotations of the pulsar, as determined by the length of an observation.</p>

<h2 id="sounds-easy-enough">Sounds easy enough</h2>

<p>The problem is that, in the absence of additional info, each candidate could potentially describe a real pulsar. <strong>However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.</strong> Thus, legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.</p>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_20_2.png" /></div>

<h2 id="the-dataset">The Dataset</h2>

<p>The data set shared here contains <strong>16,259 spurious examples caused by RFI/noise</strong>, and <strong>1,639 real pulsar examples</strong>. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).</p>

<h2 id="features-variables">Features (variables)</h2>

<p>Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency. The remaining four variables are similarly obtained from the DM-SNR curve.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Mean of the integrated profile.
* Standard deviation of the integrated profile.
* Excess kurtosis of the integrated profile.
* Skewness of the integrated profile.
* Mean of the DM-SNR curve.
* Standard deviation of the DM-SNR curve.
* Excess kurtosis of the DM-SNR curve.
* Skewness of the DM-SNR curve.
* Class
</code></pre></div></div>

<p>HTRU 2 Summary:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* 17,898 total examples
        * 1,639 positive examples
        * 16,259 negative examples
</code></pre></div></div>

<h1 id="inspect-the-dataset">Inspect the dataset</h1>

<html>
   <body>
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Mean of the integrated profile</th>
      <th>Standard deviation of the integrated profile</th>
      <th>Excess kurtosis of the integrated profile</th>
      <th>Skewness of the integrated profile</th>
      <th>Mean of the DM-SNR curve</th>
      <th>Standard deviation of the DM-SNR curve</th>
      <th>Excess kurtosis of the DM-SNR curve</th>
      <th>Skewness of the DM-SNR curve</th>
      <th>target_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>140.562500</td>
      <td>55.683782</td>
      <td>-0.234571</td>
      <td>-0.699648</td>
      <td>3.199833</td>
      <td>19.110426</td>
      <td>7.975532</td>
      <td>74.242225</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>102.507812</td>
      <td>58.882430</td>
      <td>0.465318</td>
      <td>-0.515088</td>
      <td>1.677258</td>
      <td>14.860146</td>
      <td>10.576487</td>
      <td>127.393580</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>103.015625</td>
      <td>39.341649</td>
      <td>0.323328</td>
      <td>1.051164</td>
      <td>3.121237</td>
      <td>21.744669</td>
      <td>7.735822</td>
      <td>63.171909</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>136.750000</td>
      <td>57.178449</td>
      <td>-0.068415</td>
      <td>-0.636238</td>
      <td>3.642977</td>
      <td>20.959280</td>
      <td>6.896499</td>
      <td>53.593661</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>88.726562</td>
      <td>40.672225</td>
      <td>0.600866</td>
      <td>1.123492</td>
      <td>1.178930</td>
      <td>11.468720</td>
      <td>14.269573</td>
      <td>252.567306</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</body>
</html>

<h2 id="comparing-attributes">Comparing Attributes</h2>

<h3 id="hotmap-"><code class="highlighter-rouge">Hotmap( )</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hotmap</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">)):</span>
    <span class="c1">##### correlation heatmap
</span>    <span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">mask</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">corr</span><span class="p">),</span><span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">"magma"</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">"k"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="p">),</span> <span class="o">-</span><span class="p">.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"CORRELATION BETWEEN VARIABLES"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
    
    <span class="c1">##### descriptive statistics heatmap
</span>    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()[</span><span class="mi">1</span><span class="p">:].</span><span class="n">transpose</span><span class="p">(),</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
                <span class="n">linecolor</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">"Set2"</span><span class="p">))</span> <span class="c1">#"Set2"
</span>    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="p">),</span> <span class="o">-</span><span class="p">.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Data summary"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    
    <span class="c1">### compare proportion of target classes 
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">],</span>
                       <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">"b"</span><span class="p">,</span><span class="s">"lime"</span><span class="p">],</span>
                       <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                       <span class="n">edgecolor</span><span class="o">=</span><span class="s">"k"</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">values</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">text</span><span class="p">(.</span><span class="mi">7</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">weight</span> <span class="o">=</span> <span class="s">"bold"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">27</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Count for target variable in datset"</span><span class="p">)</span>


    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">pie</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">values</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">"not pulsars"</span><span class="p">,</span><span class="s">"pulsars"</span><span class="p">],</span>
            <span class="n">autopct</span><span class="o">=</span><span class="s">"%1.0f%%"</span><span class="p">,</span><span class="n">wedgeprops</span><span class="o">=</span><span class="p">{</span><span class="s">"linewidth"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s">"edgecolor"</span><span class="p">:</span><span class="s">"white"</span><span class="p">})</span>
    <span class="n">circ</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">Circle</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),.</span><span class="mi">7</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s">"white"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">().</span><span class="n">add_artist</span><span class="p">(</span><span class="n">circ</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span> <span class="p">.</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Proportion of target variable in dataset"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">hotmap</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_20_0.png" /></div>
<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_20_1.png" /></div>
<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_20_2.png" />
</div>

<p>Target Class Values are highly differentiated for the following features:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Kurtosis Integrated Profile
* Skewness Integrated Profile
</code></pre></div></div>

<p>Other candidates include:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Mean Curve
* Standard Deviation Cruve
* Kurtosis Curve
* Skewness Curve
</code></pre></div></div>

<p>Least likely to be important in distinguishing pulsars and RFI include:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Mean Integrated Profile
* Standard Deviation IP
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># LINEPLOTS
</span><span class="n">compare</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'TARGET'</span><span class="p">)[[</span><span class="s">'MEAN_IP'</span><span class="p">,</span> <span class="s">'STD_IP'</span><span class="p">,</span> <span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="s">'SKEWNESS_IP'</span><span class="p">,</span>
                                        <span class="s">'MEAN_CURVE'</span><span class="p">,</span> <span class="s">'STD_CURVE'</span><span class="p">,</span> <span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span>
                                        <span class="s">'SKEWNESS_CURVE'</span><span class="p">]].</span><span class="n">mean</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>


<span class="n">compare</span> <span class="o">=</span> <span class="n">compare</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># compare mean of target class varibales
</span><span class="n">compare_mean</span> <span class="o">=</span> <span class="n">compare</span><span class="p">.</span><span class="n">transpose</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">compare_mean</span> <span class="o">=</span> <span class="n">compare_mean</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'index'</span><span class="p">:</span><span class="s">"features"</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s">"not_pulsar"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s">"pulsar"</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">"not_pulsar"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">compare_mean</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">"pulsar"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">compare_mean</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"lime"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"COMPARING MEAN OF ATTRIBUTES FOR TARGET CLASSES"</span><span class="p">)</span>

<span class="c1"># compare standard deviation of target class variables
</span><span class="n">compare1</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'TARGET'</span><span class="p">)[[</span><span class="s">'MEAN_IP'</span><span class="p">,</span> <span class="s">'STD_IP'</span><span class="p">,</span> <span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="s">'SKEWNESS_IP'</span><span class="p">,</span>
                                        <span class="s">'MEAN_CURVE'</span><span class="p">,</span> <span class="s">'STD_CURVE'</span><span class="p">,</span> <span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span>
                                        <span class="s">'SKEWNESS_CURVE'</span><span class="p">]].</span><span class="n">std</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">compare1</span> <span class="o">=</span> <span class="n">compare1</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'TARGET'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="n">compare_std</span> <span class="o">=</span> <span class="n">compare1</span><span class="p">.</span><span class="n">transpose</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">compare_std</span> <span class="o">=</span> <span class="n">compare_std</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'index'</span><span class="p">:</span><span class="s">"features"</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s">"not_pulsar"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s">"pulsar"</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">"not_pulsar"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">compare_std</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">"pulsar"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">compare_std</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"lime"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"COMPARING STANDARD DEVIATION OF ATTRIBUTES FOR TARGET CLASSES"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span> <span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"[GREEN == PULSAR , BLUE == NON-PULSAR]"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[GREEN == PULSAR , BLUE == NON-PULSAR]
</code></pre></div></div>

<p><img src="http://hakkeray.com/assets/images/pulsars/output_22_1.png" /></p>

<p>The mean and standard deviation of the Skewness Curve if also a good candidate predictor for our target class.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DISTRIBUTION
</span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'MEAN_IP'</span><span class="p">,</span> <span class="s">'STD_IP'</span><span class="p">,</span> <span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="s">'SKEWNESS_IP'</span><span class="p">,</span>
           <span class="s">'MEAN_CURVE'</span><span class="p">,</span> <span class="s">'STD_CURVE'</span><span class="p">,</span> <span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">]</span>
<span class="n">length</span>  <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
<span class="n">colors</span>  <span class="o">=</span> <span class="p">[</span><span class="s">"r"</span><span class="p">,</span><span class="s">"lime"</span><span class="p">,</span><span class="s">"b"</span><span class="p">,</span><span class="s">"m"</span><span class="p">,</span><span class="s">"orangered"</span><span class="p">,</span><span class="s">"c"</span><span class="p">,</span><span class="s">"k"</span><span class="p">,</span><span class="s">"orange"</span><span class="p">]</span> 

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span><span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">),</span><span class="n">colors</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">length</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">length</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span> <span class="o">=</span> <span class="p">.</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"k"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">"MEAN"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">std</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"b"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dotted"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">"STANDARD DEVIATION"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper right"</span><span class="p">)</span>
    
<span class="k">print</span> <span class="p">(</span><span class="s">"***************************************"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"DISTIBUTION OF VARIABLES IN DATA SET"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"***************************************"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>***************************************
DISTIBUTION OF VARIABLES IN DATA SET
***************************************
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_24_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s">"TARGET"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"pair plot for variables"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_25_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['MEAN_IP', 'STD_IP', 'KURTOSIS_IP', 'SKEWNESS_IP', 'MEAN_CURVE',
       'STD_CURVE', 'KURTOSIS_CURVE', 'SKEWNESS_CURVE', 'TARGET'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># SCATTERPLOTS
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

<span class="c1">##### FIRST PLOT
</span><span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'SKEWNESS_IP'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s">"PULSARS"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'cyan'</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span><span class="n">edgecolors</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'SKEWNESS_IP'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">6</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s">"NOT PULSARS"</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span><span class="s">"b"</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span><span class="n">edgecolors</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
<span class="c1">## VLINES
</span><span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'KURTOSIS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"k"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'PULSAR Mean'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'KURTOSIS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s">'NON-PULSAR Mean'</span><span class="p">)</span>
<span class="c1">## HLINES
</span><span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'SKEWNESS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"k"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'SKEWNESS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">)</span>
<span class="c1">## LABELS
</span><span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Kurtosis Integrated Profile"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Skewness Integrated Profile"</span><span class="p">)</span>
<span class="c1"># plt.title("Scatter plot for skewness and kurtosis for target classes")
</span>
<span class="c1">##### SECOND PLOT
</span><span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s">'NOT PULSARS'</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span><span class="s">"blue"</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span><span class="n">edgecolors</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s">"PULSARS"</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s">"cyan"</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span><span class="n">edgecolors</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
<span class="c1">## VLINES
</span><span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"k"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s">"PULSAR Mean"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s">"NON-PULSAR Mean"</span><span class="p">)</span>
<span class="c1">## HLINES
</span><span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"k"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
            <span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">)</span>
<span class="c1">## LABELS
</span><span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Skewness DM-SNR Curve"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Kurtosis DM-SNR Curve"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Scatter plot for skewness and kurtosis of dmsnr_curve for target classes"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_27_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># BOXPLOTS
</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'TARGET'</span><span class="p">]]</span>
<span class="n">length</span>  <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span><span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">lvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">"blue"</span><span class="p">,</span><span class="s">"cyan"</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="p">.</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">linestyle</span> <span class="o">=</span> <span class="s">"dashed"</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span><span class="s">"k"</span><span class="p">,</span>
                <span class="n">label</span> <span class="o">=</span><span class="s">"Mean value for data"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    
<span class="k">print</span> <span class="p">(</span><span class="s">"****************************************************"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"BOXPLOT FOR VARIABLES IN DATA SET WITH TARGET CLASS"</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"****************************************************"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>****************************************************
BOXPLOT FOR VARIABLES IN DATA SET WITH TARGET CLASS
****************************************************
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_28_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># STACKPLOTS
</span><span class="n">st</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">nst</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">].</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">nst</span><span class="p">,</span><span class="n">st</span><span class="p">]).</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">stackplot</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">new</span><span class="p">[</span><span class="s">'MEAN_IP'</span><span class="p">],</span>
              <span class="n">alpha</span> <span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'MEAN_IP'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">stackplot</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">new</span><span class="p">[</span><span class="s">'STD_IP'</span><span class="p">],</span>
              <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">7</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">"c"</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'STD_IP'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">stackplot</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">new</span><span class="p">[</span><span class="s">'SKEWNESS_IP'</span><span class="p">],</span>
              <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span><span class="s">"orangered"</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'SKEWNESS_IP'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">stackplot</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">new</span><span class="p">[</span><span class="s">'KURTOSIS_IP'</span><span class="p">],</span>
              <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'KURTOSIS_IP'</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">16259</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s">"black"</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span>
            <span class="n">label</span> <span class="o">=</span> <span class="s">"PULSARS vs NON-PULSARS"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="s">'MEAN_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"b"</span><span class="p">,</span>
            <span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s">"Average Mean Profile"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="s">'STD_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"c"</span><span class="p">,</span>
            <span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s">"Average Std Profile"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="s">'SKEWNESS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"orangered"</span><span class="p">,</span>
            <span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s">"Average Skewness Profile"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="s">'KURTOSIS_IP'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"magenta"</span><span class="p">,</span>
            <span class="n">linestyle</span><span class="o">=</span><span class="s">"dashed"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s">"Average Kurtosis Profile"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Area plot for attributes for pulsar stars vs non pulsar stars"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_29_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">13</span><span class="p">))</span>
<span class="n">ax</span>  <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span><span class="n">projection</span> <span class="o">=</span> <span class="s">"3d"</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][[</span><span class="s">"MEAN_IP"</span><span class="p">]],</span>
           <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][[</span><span class="s">"STD_IP"</span><span class="p">]],</span>
           <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][[</span><span class="s">"SKEWNESS_CURVE"</span><span class="p">]],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span>
           <span class="n">color</span><span class="o">=</span><span class="s">"lime"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Pulsar"</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][[</span><span class="s">"MEAN_IP"</span><span class="p">]],</span>
           <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][[</span><span class="s">"STD_IP"</span><span class="p">]],</span>
           <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"TARGET"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][[</span><span class="s">"SKEWNESS_CURVE"</span><span class="p">]],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span>
           <span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Non-Pulsar"</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"MEAN_IP"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"STD_IP"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s">"SKEWNESS_CURVE"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s">"w"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"MEAN_PROFILE VS STD_PROFILE VS SKEWNESS_DMSNR_CURVE"</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_30_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'MEAN_IP'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">'STD_IP'</span><span class="p">],</span><span class="n">kind</span><span class="o">=</span><span class="s">"kde"</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_31_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'TARGET'</span><span class="p">]]</span>
<span class="n">length</span>  <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">25</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span><span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">length</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">length</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                   <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">"blue"</span><span class="p">,</span><span class="s">"cyan"</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_32_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># BARPLOTS
</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'TARGET'</span><span class="p">]]</span>
<span class="n">length</span>  <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">25</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span><span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">length</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">length</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">],</span><span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                   <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">"blue"</span><span class="p">,</span><span class="s">"lime"</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div></div>
<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_33_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">despine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'MEAN_IP'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span>
                <span class="n">hue</span><span class="o">=</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'SKEWNESS_IP'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span>
                <span class="n">sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x123271080&gt;
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_34_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">despine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'SKEWNESS_CURVE'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span>
                <span class="n">hue</span><span class="o">=</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'MEAN_CURVE'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span>
                <span class="n">sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x124630dd8&gt;
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_35_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">despine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span>
                <span class="n">hue</span><span class="o">=</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'MEAN_CURVE'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span>
                <span class="n">sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>
<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_36_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">despine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'STD_IP'</span><span class="p">,</span>
                <span class="n">hue</span><span class="o">=</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span>
                <span class="n">sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_37_1.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.5</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">despine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'KURTOSIS_CURVE'</span><span class="p">,</span>
                <span class="n">hue</span><span class="o">=</span><span class="s">'TARGET'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s">'KURTOSIS_IP'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span>
                <span class="n">sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_38_1.png" /></div>

<h1 id="model"><code class="highlighter-rouge">MODEL</code></h1>

<h2 id="split-data">Split Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create our feature set X and labels y:
</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'TARGET'</span><span class="p">]).</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">display</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(17898,)



(17898, 8)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We'll do a 75/25 split on the dataset for training/test. 
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.33</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="construct-pipelines">Construct Pipelines</h2>

<ol>
  <li>Scale data using StandardScaler()</li>
  <li>Construct Pipelines</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># logistic regression
</span><span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">'scl'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                   <span class="p">(</span><span class="s">'pca'</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
                   <span class="p">(</span><span class="s">'clf'</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">))])</span>

<span class="c1"># support vector
</span><span class="n">pipe_svm</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">'scl'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                    <span class="p">(</span><span class="s">'pca'</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
                    <span class="p">(</span><span class="s">'clf'</span><span class="p">,</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">))])</span>


<span class="c1"># decision tree
</span><span class="n">pipe_dt</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">'scl'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                   <span class="p">(</span><span class="s">'pca'</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
                    <span class="p">(</span><span class="s">'clf'</span><span class="p">,</span> <span class="n">tree</span><span class="p">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">))])</span>

<span class="c1"># xgboost
</span><span class="n">pipe_xgb</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">'xgb'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                    <span class="p">(</span><span class="s">'pca'</span><span class="p">,</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span>
                     <span class="p">(</span><span class="s">'clf'</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">))])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># List of pipelines for ease of iteration
</span><span class="n">pipelines</span> <span class="o">=</span> <span class="p">[</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">pipe_svm</span><span class="p">,</span> <span class="n">pipe_dt</span><span class="p">,</span> <span class="n">pipe_xgb</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dictionary of pipelines and classifier types for ease of reference
</span><span class="n">pipe_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s">'Logistic Regression'</span><span class="p">,</span> 
             <span class="mi">1</span><span class="p">:</span> <span class="s">'Support Vector Machine'</span><span class="p">,</span> 
             <span class="mi">2</span><span class="p">:</span> <span class="s">'Decision Tree'</span><span class="p">,</span> 
             <span class="mi">3</span><span class="p">:</span> <span class="s">'XG Boost'</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Fit the pipelines
</span><span class="k">for</span> <span class="n">pipe</span> <span class="ow">in</span> <span class="n">pipelines</span><span class="p">:</span>
    <span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Compare accuracies
</span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pipelines</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'%s pipeline training accuracy: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">pipe_dict</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">val</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'%s pipeline test accuracy: %.3f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">pipe_dict</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">val</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logistic Regression pipeline training accuracy: 0.935
Logistic Regression pipeline test accuracy: 0.937
Support Vector Machine pipeline training accuracy: 0.955
Support Vector Machine pipeline test accuracy: 0.955
Decision Tree pipeline training accuracy: 1.000
Decision Tree pipeline test accuracy: 0.959
XG Boost pipeline training accuracy: 0.976
XG Boost pipeline test accuracy: 0.973
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Identify the most accurate model on test data
</span><span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">best_clf</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_pipe</span> <span class="o">=</span> <span class="s">''</span>


<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pipelines</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">val</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
        <span class="n">best_acc</span> <span class="o">=</span> <span class="n">val</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">best_pipe</span> <span class="o">=</span> <span class="n">val</span>
        <span class="n">best_clf</span> <span class="o">=</span> <span class="n">idx</span>
        
<span class="k">print</span><span class="p">(</span><span class="s">'Classifier with best accuracy: %s'</span> <span class="o">%</span> <span class="n">pipe_dict</span><span class="p">[</span><span class="n">best_clf</span><span class="p">])</span>

<span class="c1"># Save pipeline to file
</span><span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_pipe</span><span class="p">,</span> <span class="s">'best_pipeline.pkl'</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Saved %s pipeline to file'</span> <span class="o">%</span> <span class="n">pipe_dict</span><span class="p">[</span><span class="n">best_clf</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classifier with best accuracy: XG Boost
Saved XG Boost pipeline to file
</code></pre></div></div>

<h1 id="decision-tree"><code class="highlighter-rouge">Decision Tree</code></h1>

<p>Decision Tree</p>

<h2 id="standardize">Standardize</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Standardize the data
</span><span class="n">std</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">std</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_transformed</span> <span class="o">=</span> <span class="n">std</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="create-instance">Create Instance</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Create an instance of decision tree classifier
</span><span class="n">dt_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="fit">Fit</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Fit the training data to the model
</span><span class="n">dt_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best')
</code></pre></div></div>

<h2 id="dot-graph">DOT Graph</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create DOT data
</span><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">dt_clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                           <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>  
                           <span class="n">class_names</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="s">'str'</span><span class="p">),</span> 
                           <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Draw graph
</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>  

<span class="c1"># Show graph
</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="p">.</span><span class="n">create_png</span><span class="p">())</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_59_0.png" /></div>

<h2 id="make-predictions">Make Predictions</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make predictions for test data
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="evaluate">Evaluate</h2>

<h3 id="accuracy">Accuracy</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check the accuracy, AUC, and create a confusion matrix
</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy is :{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy is :96.56339935669544
</code></pre></div></div>

<h3 id="auc">AUC</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check the AUC for predictions
</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">AUC is :{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AUC is :0.91
</code></pre></div></div>

<h3 id="confusion-matrix">Confusion Matrix</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create and print a confusion matrix 
</span><span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Confusion Matrix'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'----------------'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s">'True'</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s">'Predicted'</span><span class="p">],</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion Matrix
----------------
</code></pre></div></div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Predicted</th>
      <th>0</th>
      <th>1</th>
      <th>All</th>
    </tr>
    <tr>
      <th>True</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5242</td>
      <td>121</td>
      <td>5363</td>
    </tr>
    <tr>
      <td>1</td>
      <td>82</td>
      <td>462</td>
      <td>544</td>
    </tr>
    <tr>
      <td>All</td>
      <td>5324</td>
      <td>583</td>
      <td>5907</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print confusion matrix
</span><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Confusion Matrix:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">cnf_matrix</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion Matrix:
 [[5242  121]
 [  82  462]]


TRUE POSITIVES: 462 Pulsars correctly identified,
TRUE NEGATIVES: 5242 correctly classified as noise
FALSE POSITIVES: 121 RFI/noise misclassified as pulsars
FALSE NEGATIVES: 82 Pulsars misclassifed as noise
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s">'Confusion matrix'</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">):</span>
    
    <span class="kn">import</span> <span class="nn">itertools</span>
    <span class="c1"># Check if normalize is set to True
</span>    <span class="c1"># If so, normalize the raw confusion matrix before visualizing
</span>    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Normalized confusion matrix"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Confusion matrix, without normalization'</span><span class="p">)</span>


    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    <span class="c1">#mask = np.zeros_like(cm, dtype=np.bool)
</span>    <span class="c1">#idx = np.triu_indices_from(mask)
</span>    
    <span class="c1">#mask[idx] = True
</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s">'equal'</span><span class="p">)</span>
    
    <span class="c1"># Add title and axis labels 
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Confusion Matrix'</span><span class="p">)</span> 
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True label'</span><span class="p">)</span> 
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted label'</span><span class="p">)</span>
    
    <span class="c1"># Add appropriate axis scales
</span>    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
    <span class="c1">#ax.set_ylim(len(cm), -.5,.5)
</span>    
    <span class="c1"># Text formatting
</span>    <span class="n">fmt</span> <span class="o">=</span> <span class="s">'.2f'</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s">'d'</span>
    <span class="c1"># Add labels to each cell
</span>    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="c1"># iterate thru matrix and append labels  
</span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                 <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'darkgray'</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s">'black'</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
    
    <span class="c1"># Add a legend
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot normalized confusion matrix
</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'Non-Pulsar'</span><span class="p">,</span> <span class="s">'Pulsar'</span><span class="p">],</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                      <span class="n">title</span><span class="o">=</span><span class="s">'Normalized confusion matrix'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Normalized confusion matrix
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_72_1.png" /></div>

<h2 id="parameter-tuning">Parameter Tuning</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Create an array for max_depth values ranging from 1 - 32
* In a loop, train the classifier for each depth value (32 runs) 
* Calculate the training and test AUC for each run
* Plot a graph to show under/over fitting and optimal value
* Interpret the results
</code></pre></div></div>

<h3 id="max-depth">Max Depth</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check for the best depth parameter
</span><span class="n">max_depths</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Identify the optimal tree depth for given data
</span><span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="n">max_depths</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
    <span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
   
    <span class="c1"># Add auc score to previous train results
</span>    <span class="n">train_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
   
    <span class="c1"># Add auc score to previous test results
</span>    <span class="n">test_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>

<span class="c1"># PLOT AUC curve
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">max_depths</span><span class="p">,</span> <span class="n">train_results</span><span class="p">,</span> <span class="s">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">max_depths</span><span class="p">,</span> <span class="n">test_results</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Test AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'AUC score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Tree depth'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'MAX TREE DEPTH'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_75_0.png" /></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max tree depth optimal value does not improve beyond 3 for test data.
</code></pre></div></div>

<h3 id="min-sample-split">Min Sample Split</h3>

<p>Now weâ€™ll check for the best min_samples_splits parameter for our decision tree.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Create an array for min_sample_splits values ranging from 0.1 - 1 with an 
increment of 0.1
* In a loop, train the classifier for each min_samples_splits value (10 runs)
* Calculate the training and test AUC for each run
* Plot a graph to show under/over fitting and optimal value
* Interpret the results
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Identify the optimal min-samples-split for given data
</span>
<span class="n">min_samples_splits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">min_samples_split</span> <span class="ow">in</span> <span class="n">min_samples_splits</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="n">min_samples_split</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
    <span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
    
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">train_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>
    
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">test_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_samples_splits</span><span class="p">,</span> <span class="n">train_results</span><span class="p">,</span> <span class="s">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_samples_splits</span><span class="p">,</span> <span class="n">test_results</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Test AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Min. Sample splits'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'AUC score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'MIN SAMPLES SPLITS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_78_0.png" /></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AUC does not improve beyond 0.2 for test data.
</code></pre></div></div>

<h3 id="minimum-sample-leafs">Minimum Sample Leafs</h3>
<p>Now weâ€™ll check for the best min_samples_leafs parameter value for our decision tree.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Create an array for min_samples_leafs values ranging from 0.1 - 0.5 
with an increment of 0.1
* In a loop, train the classifier for each min_samples_leafs value (5 runs)
* Calculate the training and test AUC for each run
* Plot a graph to show under/over fitting and optimal value
* Interpret the results
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate the optimal value for minimum sample leafs
</span><span class="n">min_samples_leafs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">min_samples_leaf</span> <span class="ow">in</span> <span class="n">min_samples_leafs</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
    <span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
    
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">train_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>
    
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">test_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>

<span class="c1"># PLOT
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>    
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_samples_leafs</span><span class="p">,</span> <span class="n">train_results</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">min_samples_leafs</span><span class="p">,</span> <span class="n">test_results</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Test AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'AUC score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Min. Sample Leafs'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'MIN SAMPLE LEAFS'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_81_0.png" /></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Highest AUC for both train and test data maximized at 0.10.
</code></pre></div></div>

<h3 id="maximum-features">Maximum Features</h3>

<p>Now weâ€™ll check for the best max_features parameter value for our decision tree.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Create an array for max_features values ranging from 1 - 12 (1 features vs all)
* In a loop, train the classifier for each max_features value (12 runs)
* Calculate the training and test AUC for each run
* Plot a graph to show under/over fitting and optimal value
* Interpret the results
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Find the best value for optimal maximum feature size
</span><span class="n">max_features</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">max_feature</span> <span class="ow">in</span> <span class="n">max_features</span><span class="p">:</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="n">max_feature</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
    <span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
    
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">train_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>
    
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">test_results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="n">train_results</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="n">test_results</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Test AUC'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'AUC score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'max features'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'MAX FEATURES'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_84_0.png" /></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Increasing parameters has no clear effect on training data (flat AUC). 
Optimal value for test data is 5.
</code></pre></div></div>

<h2 id="retrain-classifier">Retrain classifier</h2>

<p>Weâ€™ll now use the best values from each training phase above and feed it back to our classifier and see if have any improvement in predictive performance.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Train the classifier with optimal values identified
* Compare the AUC with vanilla DT AUC
* Interpret the results of comparison
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Re-train DT classifier with optimal values identified above
</span><span class="n">dt_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'entropy'</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">,</span>
                                <span class="n">max_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                <span class="n">min_samples_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># fit model
</span><span class="n">dt_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># make predictions
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>

<span class="c1"># roc_auc
</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
<span class="n">roc_auc</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9257396472014128
</code></pre></div></div>

<h3 id="dot-graph-1">DOT Graph</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create DOT data
</span><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">dt_clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                           <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>  
                           <span class="n">class_names</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="s">'str'</span><span class="p">),</span> 
                           <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Draw graph
</span><span class="n">graph</span> <span class="o">=</span> <span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>  

<span class="c1"># Show graph
</span><span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="p">.</span><span class="n">create_png</span><span class="p">())</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_89_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">modelX</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">of_type</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">"**********"</span><span class="o">*</span><span class="mi">7</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">"MODEL X"</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">"**********"</span><span class="o">*</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">algorithm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">algorithm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="k">print</span> <span class="p">(</span><span class="n">algorithm</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s"> accuracy_score :"</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    
    <span class="k">print</span> <span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">classification report :</span><span class="se">\n</span><span class="s">"</span><span class="p">,(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
        
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span> <span class="o">=</span> <span class="s">"d"</span><span class="p">,</span><span class="n">linecolor</span><span class="o">=</span><span class="s">"k"</span><span class="p">,</span><span class="n">linewidths</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"CONFUSION MATRIX"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    
    <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">algorithm</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="p">(</span><span class="s">"Area_under the curve :"</span><span class="p">,</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">)),</span><span class="n">color</span> <span class="o">=</span> <span class="s">"r"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">linestyle</span> <span class="o">=</span> <span class="s">"dashed"</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span><span class="s">"k"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">"best"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"ROC - CURVE &amp; AREA UNDER CURVE"</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">of_type</span> <span class="o">==</span> <span class="s">"feat"</span><span class="p">:</span>
        
        <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">algorithm</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
        <span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">"index"</span><span class="p">:</span><span class="s">"features"</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="s">"coefficients"</span><span class="p">})</span>
        <span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">"coefficients"</span><span class="p">,</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span><span class="s">"coefficients"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"husl"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"FEATURE IMPORTANCES"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="s">"coefficients"</span><span class="p">]):</span>
            <span class="n">ax</span><span class="p">.</span><span class="n">text</span><span class="p">(.</span><span class="mi">011</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">weight</span> <span class="o">=</span> <span class="s">"bold"</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">of_type</span> <span class="o">==</span> <span class="s">"coef"</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">algorithm</span><span class="p">.</span><span class="n">coef_</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
            <span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">"index"</span><span class="p">:</span><span class="s">"features"</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="s">"coefficients"</span><span class="p">})</span>
            <span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">"coefficients"</span><span class="p">,</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">"coefficients"</span> <span class="p">,</span><span class="n">y</span> <span class="o">=</span><span class="s">"features"</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span><span class="n">palette</span><span class="o">=</span><span class="s">"husl"</span><span class="p">)</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"FEATURE IMPORTANCES"</span><span class="p">,</span><span class="n">fontsize</span> <span class="o">=</span><span class="mi">20</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="s">"coefficients"</span><span class="p">]):</span>
                <span class="n">ax</span><span class="p">.</span><span class="n">text</span><span class="p">(.</span><span class="mi">011</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">weight</span> <span class="o">=</span> <span class="s">"bold"</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">f"</span><span class="si">{</span><span class="mi">0</span><span class="si">}</span><span class="s"> has no coef argument"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">algorithm</span><span class="p">))</span>
            

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNSCALED DATA
</span><span class="n">modelX</span><span class="p">(</span><span class="n">dt_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">"feat"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**********************************************************************
MODEL X
**********************************************************************
DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=3, max_features=5, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=0.1, min_samples_split=0.2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best')

 accuracy_score : 0.9656339935669545

classification report :
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      5363
           1       0.78      0.88      0.82       544

    accuracy                           0.97      5907
   macro avg       0.88      0.93      0.90      5907
weighted avg       0.97      0.97      0.97      5907
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_91_1.png" /></div>

<p>Kurtosis Integrated Profile (â€˜KURTOSIS_IPâ€™) is by far the most important classifying feature when it comes to identifying Pulsars. Letâ€™s double check the other metrics with our scaled/transformed data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># SCALED DATA
</span><span class="n">modelX</span><span class="p">(</span><span class="n">dt_clf</span><span class="p">,</span> <span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test_transformed</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">"coef"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**********************************************************************
MODEL X
**********************************************************************
DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=3, max_features=5, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=0.1, min_samples_split=0.2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best')

 accuracy_score : 0.9481970543423057

classification report :
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      5363
           1       0.69      0.81      0.74       544

    accuracy                           0.95      5907
   macro avg       0.83      0.88      0.86      5907
weighted avg       0.95      0.95      0.95      5907

0 has no coef argument DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
                       max_depth=3, max_features=5, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=0.1, min_samples_split=0.2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best')
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_93_1.png" />
</div>

<p><code class="highlighter-rouge">F1 Score</code>
The F1 score (also F-score or F-measure) is a measure of a testâ€™s accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.</p>

<p><code class="highlighter-rouge">Harmonic Mean</code>
<code class="highlighter-rouge">f1 = 2*(P*R / P+R)</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8245462402765774
</code></pre></div></div>

<p>Because the data involves imbalanced classes, F1 score is the most important metric for us to validate the modelâ€™s accuracy. Letâ€™s compare the Decision Tree classifier performance to XGBoost next.</p>

<h1 id="xg-boost"><code class="highlighter-rouge">XG Boost</code></h1>

<p>Moving ahead with XG Boost</p>

<h2 id="create-instance-and-fit">Create Instance and Fit</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Fit XG Boost model  
# Instantiate XGBClassifier with balanced class weights
</span><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>

<span class="c1"># Fit XGBClassifier
</span><span class="n">xgb_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)
</code></pre></div></div>

<h2 id="make-predictions-1">Make Predictions</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predict on training and test sets
</span><span class="n">training_preds</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
<span class="n">test_preds</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="evaluate-1">Evaluate</h2>

<h3 id="accuracy-1">Accuracy</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Accuracy of training and test sets
</span><span class="n">training_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">training_preds</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_preds</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Training Accuracy: {:.4}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">training_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Validation accuracy: {:.4}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Accuracy: 98.38%
Validation accuracy: 98.02%
</code></pre></div></div>

<h3 id="roc_auc-and-confusion-matrix">ROC_AUC and Confusion Matrix</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># SCALED DATA
</span><span class="n">modelX</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test_transformed</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s">"coef"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**********************************************************************
MODEL X
**********************************************************************
XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)

 accuracy_score : 0.9801929913661758

classification report :
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      5363
           1       0.92      0.86      0.89       544

    accuracy                           0.98      5907
   macro avg       0.95      0.92      0.94      5907
weighted avg       0.98      0.98      0.98      5907

0 has no coef argument XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_106_1.png" />
</div>

<h2 id="gridsearchcv">GridSearchCV</h2>

<p>Tuning XG Boost with a parameter Gridsearch</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">],</span>
    <span class="s">'min_child_weight'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s">'subsample'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
    <span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
<span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grid_clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">grid_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">grid_clf</span><span class="p">.</span><span class="n">best_params_</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Grid Search found the following optimal parameters: '</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'%s: %r'</span> <span class="o">%</span> <span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">[</span><span class="n">param_name</span><span class="p">]))</span>

<span class="n">training_preds</span> <span class="o">=</span> <span class="n">grid_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">)</span>
<span class="n">test_preds</span> <span class="o">=</span> <span class="n">grid_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
<span class="n">training_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">training_preds</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_preds</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training Accuracy: {:.4}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">training_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Validation accuracy: {:.4}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Grid Search found the following optimal parameters: 
learning_rate: 0.3
max_depth: 6
min_child_weight: 1
n_estimators: 100
subsample: 0.7

Training Accuracy: 99.96%
Validation accuracy: 97.78%
</code></pre></div></div>

<h2 id="evaluate-model">Evaluate Model</h2>

<h3 id="auc-1">AUC</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check the AUC for predictions
</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_preds</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">AUC is :{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AUC is :0.92
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare a few different regularization performances on the dataset:
</span><span class="n">C_param_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">'Set2'</span><span class="p">,</span> <span class="n">n_colors</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">C_param_range</span><span class="p">):</span>

    <span class="c1"># Predict
</span>    <span class="c1">#y_pred = tree_clf.predict(X_test)
</span>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">)</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="c1">#roc_auc = auc(fpr, tpr)
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'----------------------------------------------'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'AUC for {}: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)))</span>
    <span class="n">lw</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">n</span><span class="p">],</span>
             <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ROC curve Normalization Weight: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">n</span><span class="p">]))</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'navy'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'--'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([</span><span class="n">i</span><span class="o">/</span><span class="mf">20.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">21</span><span class="p">)])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([</span><span class="n">i</span><span class="o">/</span><span class="mf">20.0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">21</span><span class="p">)])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Receiver operating characteristic (ROC) Curve'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>----------------------------------------------
AUC for 0.005: 0.8839272493446382
----------------------------------------------
AUC for 0.1: 0.8839272493446382
----------------------------------------------
AUC for 0.2: 0.8839272493446382
----------------------------------------------
AUC for 0.3: 0.8839272493446382
----------------------------------------------
AUC for 0.5: 0.8839272493446382
----------------------------------------------
AUC for 0.6: 0.8839272493446382
----------------------------------------------
AUC for 0.7: 0.8839272493446382
----------------------------------------------
AUC for 0.8: 0.8839272493446382
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_113_1.png" /></div>

<h3 id="confusion-matrix-1">Confusion matrix</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create and print a confusion matrix 
</span><span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Confusion Matrix'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'----------------'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_preds</span><span class="p">,</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s">'True'</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s">'Predicted'</span><span class="p">],</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion Matrix
----------------
</code></pre></div></div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Predicted</th>
      <th>0</th>
      <th>1</th>
      <th>All</th>
    </tr>
    <tr>
      <th>True</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5324</td>
      <td>39</td>
      <td>5363</td>
    </tr>
    <tr>
      <td>1</td>
      <td>78</td>
      <td>466</td>
      <td>544</td>
    </tr>
    <tr>
      <td>All</td>
      <td>5402</td>
      <td>505</td>
      <td>5907</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import confusion_matrix
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># Print confusion matrix
</span><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_preds</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Confusion Matrix:</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">cnf_matrix</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion Matrix:
 [[5324   39]
 [  78  466]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot normalized confusion matrix
</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'Non-Pulsar'</span><span class="p">,</span> <span class="s">'Pulsar'</span><span class="p">],</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                      <span class="n">title</span><span class="o">=</span><span class="s">'Normalized confusion matrix'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Normalized confusion matrix
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_117_1.png" />
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot normalized confusion matrix
</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'Non-Pulsar'</span><span class="p">,</span> <span class="s">'Pulsar'</span><span class="p">],</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                      <span class="n">title</span><span class="o">=</span><span class="s">'Normalized confusion matrix'</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion matrix, without normalization
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_118_1.png" /></div>

<h2 id="mse-and-r2">MSE and R2</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">mse</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="c1"># Make predictions and evaluate 
</span>
<span class="k">print</span><span class="p">(</span><span class="s">'MSE score:'</span><span class="p">,</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'R-sq score:'</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MSE score: 0.05180294565769426
R-sq score: 0.38044238299459265
</code></pre></div></div>

<h2 id="feature-importance">Feature Importance</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Feature importance
</span><span class="n">xgb_clf</span><span class="p">.</span><span class="n">feature_importances_</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0.04194515, 0.03668287, 0.68801844, 0.03353313, 0.02772439,
       0.09195759, 0.03966612, 0.04047231], dtype=float32)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">importance</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">xgb_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">importance</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KURTOSIS_IP       0.688018
STD_CURVE         0.091958
MEAN_IP           0.041945
SKEWNESS_CURVE    0.040472
KURTOSIS_CURVE    0.039666
STD_IP            0.036683
SKEWNESS_IP       0.033533
MEAN_CURVE        0.027724
dtype: float32
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_feature_importances</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    
    <span class="n">importance</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">importance</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">importance</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">importance</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s">'center'</span><span class="p">)</span> 
    <span class="c1">#plt.yticks(np.arange(n_features), X_train.columns.values) 
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Feature importance'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Feature'</span><span class="p">)</span>

<span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_124_0.png" /></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Testing Accuracy for XG Boost Classifier: {:.4}%"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing Accuracy for XG Boost Classifier: 94.82%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Testing F1 Score for XG Boost Classifier: {:.4}%"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Testing F1 Score for XG Boost Classifier: 74.11%
</code></pre></div></div>

<h1 id="interpret-results">INTERPRET RESULTS</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Cross-Validation
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">xgb_cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mean_xgb_cv_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xgb_cv_score</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">f"Mean Cross Validation Score: </span><span class="si">{</span><span class="n">mean_xgb_cv_score</span> <span class="p">:.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean Cross Validation Score: 98.02%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Feature Importance
</span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span>

<span class="n">plot_importance</span><span class="p">(</span><span class="n">booster</span><span class="o">=</span><span class="n">xgb_clf</span><span class="p">)</span>
</code></pre></div></div>

<div style="width:400px">
<img src="http://hakkeray.com/assets/images/pulsars/output_129_1.png" /></div>

<h1 id="conclusion">CONCLUSION</h1>

<p>I began analysis with a pipeline to determine the most accurate models for predicting a pulsar. After performing Standard Scaling on the dataset, I split the dataset into train-test prediction models for Logistic Regression, Support Vector Machines, Decision Trees and XG Boost. All were fairly accurate, with Decision Trees and XG Boost topping the list for accuracy scores.</p>

<p>I then proceeded with a Decision Tree classifier with balanced class weights, which did fairly well, scoring 96% accuracy. However, because of the imbalanced classes, the F1 score is our most important validator for model accuracy, and the Decision Tree classifier scored 82%.</p>

<p>Moving on to XGBoost, the model scored 98% accuracy with an 89% F1 score. The model successfully identify 466 pulsars, missing only 78 which it mistakenly identified as noise.</p>

<h1 id="recommendations">RECOMMENDATIONS</h1>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> * Focus on Kurtosis Integrated Profile
 
 * Focus on Standard Deviation DM-NSR Curve
 
 * Validate model predictions with analysis of other celestial objects 
 producing cosmic rays to see if they show the same attributes.
</code></pre></div></div>

<h1 id="future-work">FUTURE WORK</h1>

<ol>
  <li>
    <p>Improving the model, trying other ways of scaling, balancing class weights.</p>
  </li>
  <li>
    <p>Looking at stars right before they die - predicting whether or not it will become a pulsar or not (could be slightly impossible considering stars live for billions  of yearsâ€¦)</p>
  </li>
</ol>
:ET