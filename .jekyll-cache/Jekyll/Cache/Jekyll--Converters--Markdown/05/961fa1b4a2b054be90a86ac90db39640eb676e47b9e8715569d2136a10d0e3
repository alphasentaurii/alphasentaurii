I"t<p>Predicting stroke outcomes using brain MRI images on AWS Redshift</p>

<h1 id="project-goal">Project Goal</h1>
<p>Predict age and assessment values from two domains using features derived from brain MRI images as inputs.</p>

<h1 id="background-neuroimaging">Background: Neuroimaging</h1>
<p>Human brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.</p>

<h1 id="background-trends-competition">Background: TReNDS Competition</h1>
<p>The competition(TReNDS) is meant to encourage approaches able to predict age plus additional continuous individual-level assessment values, given multimodal brain features such as 3D functional spatial maps from resting-state functional MRI, static functional network connectivity (FNC) matrices, and source-based morphometry (SBM) loading values from structural MRI. For this task, one of the largest datasets of unbiased multimodal brain imaging features is made available. Given a set of multimodal imaging features, the developed predictors should output age and assessment predictions.</p>

<h1 id="fmri-scans">fMRI Scans</h1>
<p>An fMRI scan is a functional magnetic resonance imaging scan that measures and maps the brain’s activity. An fMRI scan uses the same technology as an MRI scan. An MRI is a noninvasive test that uses a strong magnetic field and radio waves to create an image of the brain. The image an MRI scan produces is just of organs/tissue, but an fMRI will produce an image showing the blood flow in the brain. By showing the blood flow it will display which parts of the brain are being stimulated.</p>

<h1 id="predictions">Predictions</h1>
<p>We need to predict values for following output variables:</p>

<ul>
  <li>age</li>
  <li>domain1_var1</li>
  <li>domain1_var2</li>
  <li>domain2_var1</li>
  <li>domain2_var2</li>
</ul>

<h1 id="data-set">Data Set</h1>
<p><code class="highlighter-rouge">TReNDS Neuroimaging</code> : Multiscanner normative age and assessments prediction with brain function, structure, and connectivity.</p>

<p>https://www.kaggle.com/c/trends-assessment-prediction/data</p>

<h1 id="background">Background</h1>
<p>Models are expected to generalize on data from a different scanner/site (site 2). All subjects from site 2 were assigned to the test set, so their scores are not available. While there are fewer site 2 subjects than site 1 subjects in the test set, the total number of subjects from site 2 will not be revealed until after the end of the competition. To make it more interesting, the IDs of some site 2 subjects have been revealed below. Use this to inform your models about site effects. Site effects are a form of bias. To generalize well, models should learn features that are not related to or driven by site effects.</p>

<h2 id="files">Files</h2>
<p>The .mat files for this competition can be read in python using h5py, and the .nii file can be read in python using nilearn.</p>

<ul>
  <li>fMRI_train - a folder containing 53 3D spatial maps for train samples in .mat format</li>
  <li>fMRI_test - a folder containing 53 3D spatial maps for test samples in .mat format</li>
  <li>fnc.csv - static FNC correlation features for both train and test samples</li>
  <li>loading.csv - sMRI SBM loadings for both train and test samples</li>
  <li>train_scores.csv - age and assessment values for train samples</li>
  <li>sample_submission.csv - a sample submission file in the correct format</li>
  <li>reveal_ID_site2.csv - a list of subject IDs whose data was collected with a different scanner than the train samples</li>
  <li>fMRI_mask.nii - a 3D binary spatial map</li>
  <li>ICN_numbers.txt - intrinsic connectivity network numbers for each fMRI spatial map; matches FNC names</li>
</ul>

<h1 id="disclaimer-from-kaggle">Disclaimer (from Kaggle)</h1>

<p>The scores (see train_scores.csv) are not the original age and raw assessment values. They have been transformed and de-identified to help protect subject identity and minimize the risk of unethical usage of the data. Nonetheless, they are directly derived from the original assessment values and, thus, associations with the provided features is equally likely.</p>

<p>Before transformation, the age in the training set is rounded to nearest year for privacy reasons. However, age is not rounded to year (higher precision) in the test set. Thus, heavily overfitting to the training set age will very likely have a negative impact on your submissions.</p>

<h1 id="how-features-were-obtained">How Features Were Obtained</h1>
<p>An unbiased strategy was utilized to obtain the provided features. This means that a separate, unrelated large imaging dataset was utilized to learn feature templates. Then, these templates were “projected” onto the original imaging data of each subject used for this competition using spatially constrained independent component analysis (scICA) via group information guided ICA (GIG-ICA).</p>

<h1 id="1st-set">1st set</h1>
<p><code class="highlighter-rouge">Source-based morphometry (SBM) loadings</code>: These are subject-level weights from a group-level ICA decomposition of gray matter concentration maps from structural MRI (sMRI) scans.</p>

<h1 id="2nd-set">2nd set</h1>
<p><code class="highlighter-rouge">Static functional network connectivity (FNC) matrices</code>: These are the subject-level cross-correlation values among 53 component timecourses estimated from GIG-ICA of resting state functional MRI (fMRI).</p>

<h1 id="3rd-set">3rd set</h1>
<p><code class="highlighter-rouge">Component spatial maps (SM)</code>: These are the subject-level 3D images of 53 spatial networks estimated from GIG-ICA of resting state functional MRI (fMRI).</p>

<h1 id="optional-use-aws-redshift-for-data-repository">Optional: Use AWS Redshift for Data Repository</h1>
<p>See my blog post on <a href="configuring and querying AWS Redshift">/blog/datascience/2020/08/08/aws-redshift-configuration.html</a> for housing the data (~160GB) instead of using your local machine.</p>

<h1 id="import-data">Import data</h1>

<p>Use the kaggle API to download dataset</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kaggle competitions download <span class="nt">-c</span> trends-assessment-prediction
</code></pre></div></div>

:ET