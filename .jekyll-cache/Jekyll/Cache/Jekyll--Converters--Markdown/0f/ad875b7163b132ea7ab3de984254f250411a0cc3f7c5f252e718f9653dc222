I"<p>The vision for <code class="highlighter-rouge">Starskøpe</code> : cyberoptic artificial telescope is to aggregate large datasets from multiple missions in order to give us a more accurate, more detailed picture of the stars and planets than what we have available to us in the limited view of a single picture from a single telescope at a single point in time.</p>

<p><em>This is a continuation of the Starskøpe Project:</em>
<a href="/datascience/2020/04/01/starskope-cyberoptic-artificial-telescope.html">STARSKØPE I</a>
<a href="/datascience/2020/05/06/spectrograph-image-classification.html">STARSKØPE II</a></p>

<h2 id="starskøpe-phase-3-objectives">STARSKØPE Phase 3 Objectives</h2>

<ol>
  <li>
    <p>Use datasets from the MAST website (via API) to incorporate other calculations of the star’s properties as features to be used for classification algorithms. Furthermore, attempt other types of transformations and normalizations on the data before running the model - for instance, apply a Fourier transform.</p>
  </li>
  <li>
    <p>Combine data from multiple campaigns and perhaps even multiple telescopes (for instance, matching sky coordinates and time intervals between K2, Kepler, and TESS for a batch of stars that have overlapping observations - this would be critical for finding transit periods that are longer than the campaigns of a single telecope’s observation period).</p>
  </li>
  <li>
    <p>Explore using computer vision on not only the Full Frame images we can collect from telescopes like TESS, but also on spectographs of the flux values themselves. The beauty of machine learning is our ability to rely on the computer to pick up very small nuances in differences that we ourselves cannot see with our own eyes.</p>
  </li>
  <li>
    <p>Explore using autoencoded machine learning algorithms with Restricted Boltzmann Machines - this type of model has proven to be incredibly effective in the image analysis of handwriting as we’ve seen applied the MNIST dataset - let’s find out if the same is true for images of stars, be they the Full Frame Images or spectographs.</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This script queries MAST for TESS FFI data for a single sector/camera/chip 
# combination and downloads the data from the AWS public dataset rather than 
# from MAST servers.
</span>
<span class="c1"># Working with http://astroquery.readthedocs.io/en/latest/mast/mast.html
# Make sure you're running the latest version of Astroquery:
# pip install https://github.com/astropy/astroquery/archive/master.zip
</span>
<span class="kn">from</span> <span class="nn">astroquery.mast</span> <span class="kn">import</span> <span class="n">Observations</span>
<span class="kn">import</span> <span class="nn">boto3</span>

<span class="c1"># Query for observations in sector 1 (s0001), camera 1, chip 1 (1-1)
</span><span class="n">obsTable</span> <span class="o">=</span> <span class="n">Observations</span><span class="p">.</span><span class="n">query_criteria</span><span class="p">(</span><span class="n">obs_id</span><span class="o">=</span><span class="s">"tess-s0001-1-1"</span><span class="p">)</span>

<span class="c1"># Get the products associated with these observations
</span><span class="n">products</span> <span class="o">=</span> <span class="n">Observations</span><span class="p">.</span><span class="n">get_product_list</span><span class="p">(</span><span class="n">obsTable</span><span class="p">)</span>

<span class="c1"># Return only the calibrated FFIs (.ffic.fits)
</span><span class="n">filtered</span> <span class="o">=</span> <span class="n">Observations</span><span class="p">.</span><span class="n">filter_products</span><span class="p">(</span><span class="n">products</span><span class="p">,</span> 
                                        <span class="n">productSubGroupDescription</span><span class="o">=</span><span class="s">"FFIC"</span><span class="p">,</span>
                                        <span class="n">mrp_only</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>
<span class="c1"># &gt; 1282
</span>
<span class="c1"># Enable 'cloud mode' for module which will return S3-like URLs for FITs files
# e.g. s3://stpubdata/tess/.../tess2018206192942-s0001-1-1-0120-s_ffic.fits
</span><span class="n">Observations</span><span class="p">.</span><span class="n">enable_cloud_dataset</span><span class="p">()</span>

<span class="c1"># Grab the S3 URLs for each of the observations
</span><span class="n">s3_urls</span> <span class="o">=</span> <span class="n">Observations</span><span class="p">.</span><span class="n">get_cloud_uris</span><span class="p">(</span><span class="n">filtered</span><span class="p">)</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="n">resource</span><span class="p">(</span><span class="s">'s3'</span><span class="p">)</span>

<span class="c1"># Create an authenticated S3 session. Note, download within US-East is free
# e.g. to a node on EC2.
</span><span class="n">s3_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="n">client</span><span class="p">(</span><span class="s">'s3'</span><span class="p">,</span>
                         <span class="n">aws_access_key_id</span><span class="o">=</span><span class="s">'YOURAWSACCESSKEY'</span><span class="p">,</span>
                         <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="s">'YOURSECRETACCESSKEY'</span><span class="p">)</span>

<span class="n">bucket</span> <span class="o">=</span> <span class="n">s3</span><span class="p">.</span><span class="n">Bucket</span><span class="p">(</span><span class="s">'stpubdata'</span><span class="p">)</span>

<span class="c1"># Just download a few of the files (remove the [0:3] to download them all)
</span><span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">s3_urls</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]:</span>
  <span class="c1"># Extract the S3 key from the S3 URL
</span>  <span class="n">fits_s3_key</span> <span class="o">=</span> <span class="n">url</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"s3://stpubdata/"</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
  <span class="n">root</span> <span class="o">=</span> <span class="n">url</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">bucket</span><span class="p">.</span><span class="n">download_file</span><span class="p">(</span><span class="n">fits_s3_key</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">ExtraArgs</span><span class="o">=</span><span class="p">{</span><span class="s">"RequestPayer"</span><span class="p">:</span> <span class="s">"requester"</span><span class="p">})</span>
  
</code></pre></div></div>
:ET