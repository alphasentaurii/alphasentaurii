I"é<h2 id="building-a-cyberoptic-artificial-telescope-for-astrophysical-object-classification">Building a Cyberoptic Artificial Telescope for Astrophysical Object Classification</h2>
<blockquote>
  <p>‚ÄúMathematicians [‚Ä¶] are often led astray when ‚Äòstudying‚Äô physics because they lose sight of the physics. They say: <em>‚ÄòLook, these differential equations‚Äìthe Maxwell equations‚Äìare all there is to electrodynamics; it is admitted by the physicists that there is nothing which is not contained in the equations. The equations are complicated, but after all they are only mathematical equations and if I understand them mathematically inside out, I will understand the physics inside out.‚Äô</em> Only it doesn‚Äôt work that way. Mathematicians who study physics with that point of view‚Äìand there have been many of them‚Äìusually make little contribution to physics and, in fact, little to mathematics. They fail because the actual physical situations in the real world are so complicated that it is necessary to have a much broader understanding of the equations.‚Äù
<strong>-Richard Feynman, <em>The Feynman Lectures on Physics: Volume 2</em>, Chapter 2-1: ‚ÄúDifferential Calculus of Vector Fields‚Äù</strong></p>

</blockquote>

<p><img src="/assets/images/starskope/feynman-bongos.jpg" width="400" /></p>

<h2 id="introduction">INTRODUCTION</h2>

<p>One of the reasons I quote Mr. Feynman above is because I set out to work on this project with only one year of high school physics under my belt. Despite loving the subject and even getting an A- in that one class, for some reason I did not continue pursuing physics while in school. I bought the Feynman lectures a few years back (on a whim? who does that?) and as soon as I began preparing for this project I felt intuitively that it would be somewhat ridiculous for me to build neural networks for classifying astrophysical data if I didn‚Äôt fully grasp how and why the equations used to calculate my findings actually work.</p>

<h2 id="questions">QUESTIONS</h2>
<p>The specific questions this project seeks to answer are as follows:</p>

<ol>
  <li>
    <p>Can a transiting exoplanet be detected strictly by analyzing the raw flux values of a given star?</p>
  </li>
  <li>
    <p>What is the best approach for pre-processing photometric timeseries data and what are some of the issues we might encounter in choosing how the data is prepared for classification modeling?</p>
  </li>
  <li>
    <p>How much signal-to-noise ratio is too much? That is, if the classes are highly imbalanced, for instance only a few planets can be confirmed out of thousands of stars, does the imbalance make for an unreliable or inaccurate model?</p>
  </li>
  <li>
    <p>How do we test and validate that?</p>
  </li>
</ol>

<h2 id="dataset">DATASET</h2>

<p>To answer the above questions, I started the analysis with a small labeled timeseries dataset from Kaggle posted by NASA several years ago. The reason I chose this particular dataset is because in terms of the type of information we typically need to know in order to solve a physics problem ‚Äì the primary one being UNITS, otherwise it‚Äôs a math problem! ‚Äì this one is barren. The author who posted the dataset (<code class="highlighter-rouge">Winter Delta</code> or <code class="highlighter-rouge">W‚àÜ</code>) does however give us a few hints on how we <em>could</em> determine the units, and the dimensions, and a lot of other important physics-related information, if we do a little research. The biggest hint is that this dataset is from the K2 space telescope‚Äôs Campaign 3 observations in which only 42 confirmed exoplanets are detected in a set of over 5,000 stars. Looking at the dataset on its own (before doing any digging), we are given little information about how long the time period covers, and we know do not know what the time intervals between flux values are. So far, this has not stopped any data scientists from attempting to tackle the classification model without gathering any additional information.</p>

<p><img src="/assets/images/starskope/288_planetbleed1600.jpeg" width="600" />
source: NASA</p>

<h2 id="model">MODEL</h2>

<p>To answer the question, I first set out to build a model for the data as is, ‚Äúsans-physics‚Äù. The baseline model is a neural network using the <code class="highlighter-rouge">Keras API</code> in a <code class="highlighter-rouge">sci-kit learn</code> wrapper.</p>

<h2 id="results">RESULTS</h2>

<p>I was able to identify with 99% accuracy the handful of stars (5) in the test dataset that have a confirmed exoplanet in their orbit. This baseline model is mathematically accurate, but it does not ‚Äúunderstand physics‚Äù. The conclusion we need to make about the model is whether or not this lack of physics embedded in the training process (or even pre-training process) is acceptable or not.</p>

<h2 id="conclusion">CONCLUSION</h2>

<p>While it is possible to create a 99% accurate machine learning model for detecting exoplanets using the raw flux values, without any sense of the actual time intervals, and with a highly imbalanced data set (imbalanced meaning only a few positive examples in a sea of negatives) - it is unclear that we can ‚Äúget away with‚Äù this in every case. Furthermore, it is unlikely that could feel completely sure that we aren‚Äôt missing out on critical information - such as detecting the existence of an earth-like exoplanet transiting a star - if we don‚Äôt use our understanding of physics to further de-noise, normalize, and scale the data before training the model (and possibly even embed this into a pre-training phase). As a case in point, if you read any of the space telescope handbooks, you will quickly learn just how complex the instruments that are producng this data are, and that the way their technology works, when and where in the sky they were pointing, as well as what actually happened during their missions, you‚Äôd know that should all probably be taken into account in your model! The K2 data in particular, for instance, has a unique issue that every so often its thrusters would fire to adjust/maintain its position in the sky, causing data at multiple points to be completely useless.</p>

<h2 id="why-that-matters">Why that matters‚Ä¶</h2>

<p>This type of noise cannot be removed without knowing what exact times the thrusters fired, as well as what times each of the observations of the dataset occurred. Even if we do manage to throw the bad data out, we are still stuck with the problem of not having any data for that time period, and once again might miss our potential planet‚Äôs threshold crossing event! If we know where and when those missing pieces occur, we could use that to collect our missing data from another telescope like TESS, which has overlapping targets of observation. A model that can combine data from two different space telescopes, and be smart enough to know based on the telescope it came from how to handle the data, would make truly accurate predictions, and much more useful classifications.</p>

<h2 id="what-we-can-do-about-that">What we can do about that‚Ä¶</h2>

<p>This is the type of model I will set out to build in my future work. This is what we would call a cyberoptic artificial telescope - one that can aggregate large datasets from multiple missions and give us a more accurate, more detailed picture of the stars and planets than what we have available to us in the limited view of a single picture from a single telescope at a single point in time. This is the vision for <em>STARSK√òPE</em> which will come out of this project.</p>

<h2 id="recommendations">RECOMMENDATIONS</h2>

<p>My recommendations are the following:</p>

<ol>
  <li>
    <p>Use datasets from the MAST website (via API) to incorporate other calculations of the star‚Äôs properties as features to be used for classification algorithms. Furthermore, attempt other types of transformations and normalizations on the data before running the model - for instance, apply a Fourier transform.</p>
  </li>
  <li>
    <p>Combine data from multiple campaigns and perhaps even multiple telescopes (for instance, matching sky coordinates and time intervals between K2, Kepler, and TESS for a batch of stars that have overlapping observations - this would be critical for finding transit periods that are longer than the campaigns of a single telecope‚Äôs observation period).</p>
  </li>
  <li>
    <p>Explore using computer vision on not only the Full Frame images we can collect from telescopes like TESS, but also on spectographs of the flux values themselves. The beauty of machine learning is our ability to rely on the computer to pick up very small nuances in differences that we ourselves cannot see with our own eyes.</p>
  </li>
  <li>
    <p>Explore using autoencoded machine learning algorithms with Restricted Boltzmann Machines - this type of model has proven to be incredibly effective in the image analysis of handwriting as we‚Äôve seen applied the MNIST dataset - let‚Äôs find out if the same is true for images of stars, be they the Full Frame Images or spectographs.</p>
  </li>
</ol>

<h2 id="future-work">FUTURE WORK</h2>
<p>To continue this project, I‚Äôll take another approach for detecting exoplanets using computer vision to analyze images of spectographs of this same star flux data set. Please go to the next post <a href="/datascience/2020/05/06/starskope-2-spectrograph-image-classification.html">starskope-2</a> to see how I build a <code class="highlighter-rouge">convolutional neural network</code> to classify stars using spectrograph images of the flux values to find transiting exoplanets. Following this, I apply the same algorithm to spectrographs of Fourier transformed data.</p>

<p>Additional future work following this project will be to develop my ‚Äúcyberoptic artificial telescope‚Äù as a machine learning driven application that any astrophysicist can use to look at a single or collection of stars and have the model classify them according not only to exoplanet predictions, but also predict what type of star it is, and other key properties that would be of interest for astrophysical science applications.</p>

<h2 id="scrub">SCRUB</h2>
<p><strong>Initial inspection of data, reviewing the features, target (if any), datatypes, and checking for nulls.</strong></p>

<p>Each star‚Äôs light frequency makes up a single row of data collected over the course of the campaign (#3), which in this case for K2 campaign 3 was a little over 60 days (campaigns are normally ~80 days but c3 ended early due to data storage capacity issues.</p>

<p>If we crunched the numbers (which I did elsewhere), it‚Äôs 29.4 minutes between each flux measurement, also known as the cadence. This matches the information available in the K2 handbook/MAST website/NASA. Knowing the units and time intervals would allow us to scale and normalize the data very methodically. However, since our initial (math-based) model doesn‚Äôt ‚Äòcare‚Äô about units, the scrubbing will not take any of the physics into account. This is intentional.</p>

<p>This is something we DO want to come back to for comparison with future models that <em>will</em> have the astrophysical properties embedded in their pre-learning process, and in particular the SCRUBBING: remember, this is a <em>timeseries</em>‚Ä¶it‚Äôs hard to do any normalizing, scaling, de-noising to a timeseries if we don‚Äôt know anything about the time units. And that‚Äôs only ONE of the dimensions being completely ignored by our strict mathematical approach. The question is, will it matter?</p>

<h3 id="initial-inspection">Initial Inspection</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Check the value counts 
</span><span class="n">display</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'LABEL'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(),</span><span class="n">test</span><span class="p">[</span><span class="s">'LABEL'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1    5050
2      37
Name: LABEL, dtype: int64



1    565
2      5
Name: LABEL, dtype: int64
</code></pre></div></div>

<h3 id="target">TARGET</h3>
<p>Our target column <code class="highlighter-rouge">LABEL</code> assigns each star with a 1 or a 2 to designate whether or not there is a confirmed exoplanet that was found in the star‚Äôs orbit. This is precisely what we are trying to classify in our model below.</p>

<p>Notice there are a total of only 42 stars that are labeled ‚Äú2‚Äù, ie confirmed exoplanet orbiting this star. There are 37 exoplanet host stars in the training set, and only 5 in the test set. Such highly imbalanced classes will be something we need to deal with carefully in our model.</p>

<h2 id="explore">Explore</h2>

<h3 id="planet-host-vs-non-host-stars">Planet Host vs Non-Host Stars</h3>

<p>Since we are setting out to classify stars as being either a planet-host or non-host, it would be useful to compare the data visually and see if we can pick up on any significant differences in the flux values with just our eyeballs. The simplest way to do this is plot the signals of each target class for a couple of stars and look at the scatter plots and a line plots.</p>

<h3 id="threshold-crossing-event-tce">Threshold Crossing Event (TCE)</h3>
<p>TCE is determined by a significant dip in the flux values, the assumption being something crossed in front of the star blocking its light for some period of time that the telescope has designated as suspect of an orbiting planet! The occurrence of a TCE means that star is flagged as a ‚ÄòTarget of Interest‚Äô or in K2‚Äôs case, ‚ÄòKepler Object of Ineterst‚Äô (KOI). The KOIs for each campaign have to be confirmed by a human, of course, usually an astrophysicist, and that is precisely where machine learning comes in - there are billions and billions of stars, and thus billions of billions of potential data points. ‚ÄúLooking for a needle in a haystack‚Äù doesn‚Äôt even work as a metaphor for a scale this immense. This is the ultimate challenge for data scientists! Let‚Äôs see what this looks like.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># grab first row of observations to create pandas series 
</span>
<span class="c1"># first row is label = 2 which is a confirmed exoplanet host star
# TCE "Threshold Crossing Event"
</span><span class="n">tce1</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">tce2</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># last row is label = 1 (no tce meaning no evidence this star hosts a planet)
</span><span class="n">no_tce1</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">no_tce2</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>

<span class="n">display</span><span class="p">(</span><span class="n">tce1</span><span class="p">.</span><span class="n">head</span><span class="p">(),</span><span class="n">tce2</span><span class="p">.</span><span class="n">head</span><span class="p">(),</span><span class="n">no_tce1</span><span class="p">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">no_tce2</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LABEL      2.00
FLUX.1    93.85
FLUX.2    83.81
FLUX.3    20.10
FLUX.4   -26.98
Name: 0, dtype: float64



LABEL      2.00
FLUX.1   -38.88
FLUX.2   -33.83
FLUX.3   -58.54
FLUX.4   -40.09
Name: 1, dtype: float64



LABEL       1.00
FLUX.1    323.28
FLUX.2    306.36
FLUX.3    293.16
FLUX.4    287.67
Name: 5086, dtype: float64



LABEL     1.00
FLUX.1    3.82
FLUX.2    2.09
FLUX.3   -3.29
FLUX.4   -2.88
Name: 5085, dtype: float64
</code></pre></div></div>

<h3 id="a-word-on-units">A Word on Units..</h3>

<p>After doing a little research (mostly by reading the K2 Handbook and visiting the MAST website where NASA houses all of its space telescope data) we learn that the flux values for campaign 3 that are in the Kaggle dataset have been put through a de-noising process. Prior to this particular de-noising process, the flux values would be called <code class="highlighter-rouge">SAP Flux</code> however in this case we are dealing with <code class="highlighter-rouge">PDC_SAP Flux</code>. At the moment the units may not seem to matter much, since we assume they are consist across all observations. However, as with anything relating to physics, and science for that matter, the units MATTER. All that to say, for now we are at least going to label the axes accurately so that later down the line if we want to compare this dataset to another from the archive, we will know the units! :)</p>

<h3 id="atomic_vector_plotter">atomic_vector_plotter()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">atomic_vector_plotter</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> 
     <span class="n">y_units</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">x_units</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         <span class="s">"""
         Plots scatter and line plots of time series signal values.  
        
         **ARGS
         signal: pandas series or numpy array
         label_col: name of the label column if using labeled pandas series
             -use default None for numpy array or unlabeled series.
             -this is simply for customizing plot Title to include classification    
         classes: (optional- req labeled data) tuple if binary, array if multiclass
         class_names: tuple or array of strings denoting what the classes mean
         figsize: size of the figures (default = (15,5))
        
         ******
        
        Ex1: Labeled timeseries passing 1st row of pandas dataframe
         &gt; first create the signal:
         star_signal_alpha = x_train.iloc[0, :]
         &gt; then plot:
         star_signals(star_signal_alpha, label_col='LABEL',classes=[1,2], 
                     class_names=['No Planet', 'Planet']), figsize=(15,5))
       
         Ex2: numpy array without any labels
         &gt; first create the signal:
        
         &gt;then plot:
         star_signals(signal, figsize=(15,5))
        
         ######
         TODO: 
         -`signal` should take an array rather than pdseries
         -could allow either array or series to be passed, conv to array if series 
         ######
         """</span>
        
         <span class="c1"># pass None to label_col if unlabeled data, creates generic title
</span>         <span class="k">if</span> <span class="n">label_col</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">label</span> <span class="o">=</span> <span class="bp">None</span>
             <span class="n">title_scatter</span> <span class="o">=</span> <span class="s">"Scatterplot of Star Flux Signals"</span>
             <span class="n">title_line</span> <span class="o">=</span> <span class="s">"Line Plot of Star Flux Signals"</span>
             <span class="n">color</span><span class="o">=</span><span class="s">'black'</span>
            
         <span class="c1"># store target column as variable 
</span>         <span class="k">elif</span> <span class="n">label_col</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">label</span> <span class="o">=</span> <span class="n">signal</span><span class="p">[</span><span class="n">label_col</span><span class="p">]</span>
             <span class="c1"># for labeled timeseries
</span>             <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                 <span class="n">cn</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'red'</span>

             <span class="k">elif</span> <span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                 <span class="n">cn</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> 
                <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span>
         <span class="c1">#create appropriate title acc to class_names    
</span>             <span class="n">title_scatter</span> <span class="o">=</span> <span class="s">f"Scatterplot for Star Flux Signal: </span><span class="si">{</span><span class="n">cn</span><span class="si">}</span><span class="s">"</span>
             <span class="n">title_line</span> <span class="o">=</span> <span class="s">f"Line Plot for Star Flux Signal: </span><span class="si">{</span><span class="n">cn</span><span class="si">}</span><span class="s">"</span>
        
         <span class="c1"># Set x and y axis labels according to units
</span>         <span class="c1"># if the units are unknown, we will default to "Flux"
</span>         <span class="k">if</span> <span class="n">y_units</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">y_units</span> <span class="o">=</span> <span class="s">'Flux'</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="n">y_units</span> <span class="o">=</span> <span class="n">y_units</span>
         <span class="c1"># it is assumed this is a timeseries, default to "time"   
</span>         <span class="k">if</span> <span class="n">x_units</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">x_units</span> <span class="o">=</span> <span class="s">'Time'</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="n">x_units</span> <span class="o">=</span> <span class="n">x_units</span>
        
         <span class="c1"># Scatter Plot 
</span>        
         <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">signal</span><span class="p">))]),</span> 
                     <span class="n">signal</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">marker</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_units</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">x_units</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title_scatter</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

         <span class="c1"># Line Plot
</span>         <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">signal</span><span class="p">))]),</span> 
                 <span class="n">signal</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_units</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">x_units</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title_line</span><span class="p">)</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">spacekit.analyzer</span> <span class="kn">import</span> <span class="n">Flux</span>

<span class="n">Flux</span><span class="p">.</span><span class="n">atomic_vector_plotter</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="n">tce1</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s">'LABEL'</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> 
         <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span> <span class="s">'Planet'</span><span class="p">],</span> 
         <span class="n">y_units</span><span class="o">=</span><span class="s">'PDC_SAP Flux'</span><span class="p">,</span> <span class="n">x_units</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span>

<span class="n">Flux</span><span class="p">.</span><span class="n">atomic_vector_plotter</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="n">tce2</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s">'LABEL'</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
         <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span> <span class="s">'Planet'</span><span class="p">],</span>
         <span class="n">y_units</span><span class="o">=</span><span class="s">'PDC_SAP Flux'</span><span class="p">,</span> <span class="n">x_units</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_32_0.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_32_1.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_32_2.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_32_3.png" width="400" /></p>

<p>This second star‚Äôs flux signal pattern looks very different - are we to assume that each one of those dips is a transit event? Perhaps more than one planet is orbiting? Otherwise that would be a fairly short period. Let‚Äôs compare these to the NON planet host stars:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Flux</span><span class="p">.</span><span class="n">atomic_vector_plotter</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="n">no_tce1</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s">'LABEL'</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
                         <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span> <span class="s">'Planet'</span><span class="p">],</span>
                          <span class="n">y_units</span><span class="o">=</span><span class="s">'PDC_SAP Flux'</span><span class="p">,</span> <span class="n">x_units</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span>

<span class="n">Flux</span><span class="p">.</span><span class="n">atomic_vector_plotter</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="n">no_tce2</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s">'LABEL'</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
                         <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span> <span class="s">'Planet'</span><span class="p">],</span>
                          <span class="n">y_units</span><span class="o">=</span><span class="s">'PDC_SAP Flux'</span><span class="p">,</span> <span class="n">x_units</span><span class="o">=</span><span class="s">'Time'</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_34_0.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_34_1.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_34_2.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_34_3.png" width="400" /></p>

<p>It‚Äôs hard to make a fair comparison with these plots without being able to see much in detail. We need to ‚Äúzoom in‚Äù - this can be accomplished through normalizing and scaling techniques, but the standard procedure for this type of data would be to perform <code class="highlighter-rouge">phase-folding</code> based on the estimated period of the transiting planets.</p>

<h2 id="pre-processing">Pre-processing</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">spacekit.transformer</span> <span class="kn">import</span> <span class="n">Transformer</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">.</span><span class="n">Transformer</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="hypersonic_pliers">hypersonic_pliers()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">hypersonic_pliers</span><span class="p">(</span><span class="n">path_to_train</span><span class="p">,</span> <span class="n">path_to_test</span><span class="p">):</span>
        
         <span class="s">"""
         Using Numpy to extract data into 1-dimensional arrays
         separate target classes (y) for training and test data
         assumes y (target) is first column in dataframe
       
         #TODO: option to pass in column index loc for `y` if not default (0) 
         #TODO: option for `y` to already be 0 or 1 (don't subtract 1)
         #TODO: allow option for `y` to be categorical (convert via binarizer)
         """</span>
         <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
       
         <span class="n">Train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path_to_train</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>
         <span class="n">X_train</span> <span class="o">=</span> <span class="n">Train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
         <span class="n">y_train</span> <span class="o">=</span> <span class="n">Train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.</span>
       
         <span class="n">Test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path_to_test</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>
         <span class="n">X_test</span> <span class="o">=</span> <span class="n">Test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
         <span class="n">y_test</span> <span class="o">=</span> <span class="n">Test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.</span>
        
         <span class="k">del</span> <span class="n">Train</span><span class="p">,</span><span class="n">Test</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"X_train: "</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"y_train: "</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"X_test: "</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"y_test: "</span><span class="p">,</span> <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        
         <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">hypersonic_pliers</span><span class="p">(</span><span class="n">DATA</span><span class="o">+</span><span class="s">'/exoTrain.csv'</span><span class="p">,</span> 
                                          <span class="n">DATA</span><span class="o">+</span><span class="s">'/exoTest.csv'</span><span class="p">)</span> 
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X_train:  (5087, 3197)
y_train:  (5087, 1)
X_test:  (570, 3197)
y_test:  (570, 1)
</code></pre></div></div>

<h3 id="scaling-thermo_fusion_chisel">Scaling: thermo_fusion_chisel()</h3>

<p>Scale each observation to zero mean and unit variance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">thermo_fusion_chisel</span><span class="p">(</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">matrix2</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
             <span class="s">"""
             Scales each array of a matrix to zero mean and unit variance.
             returns matrix/matrices of same shape as input but scaled
             matrix2 is optional - useful if data was already train-test split
             example: matrix1=X_train, matrix2=X_test
           
             """</span>
             <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
           
               
             <span class="n">matrix1</span> <span class="o">=</span> <span class="p">((</span><span class="n">matrix1</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> 
                 <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
           
             <span class="k">print</span><span class="p">(</span><span class="s">"Mean: "</span><span class="p">,</span><span class="n">matrix1</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span>
             <span class="k">print</span><span class="p">(</span><span class="s">"Variance: "</span><span class="p">,</span><span class="n">matrix1</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">std</span><span class="p">())</span>
           
             <span class="k">if</span> <span class="n">matrix2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                 <span class="n">matrix2</span> <span class="o">=</span> <span class="p">((</span><span class="n">matrix2</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">matrix2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> 
                     <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">matrix2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
           
                 <span class="k">print</span><span class="p">(</span><span class="s">"Mean: "</span><span class="p">,</span><span class="n">matrix2</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span>
                 <span class="k">print</span><span class="p">(</span><span class="s">"Variance: "</span><span class="p">,</span><span class="n">matrix2</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">std</span><span class="p">())</span>
                 <span class="k">return</span> <span class="n">matrix1</span><span class="p">,</span><span class="n">matrix2</span>
             <span class="k">else</span><span class="p">:</span>
                 <span class="k">return</span> <span class="n">matrix1</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Scale each row to zero mean and unit variance.
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">thermo_fusion_chisel</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean:  0.0
Variance:  1.0
Mean:  2.6670356049800446e-17
Variance:  1.0
</code></pre></div></div>

<h3 id="de-noising-babel_fish_dispenser">De-noising: babel_fish_dispenser()</h3>

<p>In order to reduce the amount of high frequency noise that is likely to have an adverse effect on the neural network‚Äôs learning outcomes, we can pass a uniform 1-D filter on our scaled train and test data then stack the arrays along the second axis. There are other techniques we might want to apply for further de-noising but for now we‚Äôll start with this for the baseline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5087, 3197)
(5087, 1)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">babel_fish_dispenser</span><span class="p">(</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">matrix2</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
         <span class="s">"""        
         Adds an input corresponding to the running average over a set number
         of time steps. This helps the neural network to ignore high frequency 
         noise by passing in a uniform 1-D filter and stacking the arrays. 
         **ARGS
         step_size: integer, # timesteps for 1D filter. defaults to 200
         axis: which axis to stack the arrays

         ex:
         noise_filter(matrix1=X_train, matrix2=X_test, step_size=200)
         """</span>
         <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
         <span class="kn">from</span> <span class="nn">scipy.ndimage.filters</span> <span class="kn">import</span> <span class="n">uniform_filter1d</span>

         <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">step_size</span><span class="o">=</span><span class="mi">200</span>

         <span class="c1"># calc input for flux signal rolling avgs 
</span>         <span class="n">filter1</span> <span class="o">=</span> <span class="n">uniform_filter1d</span><span class="p">(</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
         <span class="c1"># store in array and stack on 2nd axis for each obs of X data
</span>         <span class="n">matrix1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">matrix1</span><span class="p">,</span> <span class="n">filter1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

         <span class="k">if</span> <span class="n">matrix2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">filter2</span> <span class="o">=</span> <span class="n">uniform_filter1d</span><span class="p">(</span><span class="n">matrix2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
             <span class="n">matrix2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">matrix2</span><span class="p">,</span> <span class="n">filter2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
             <span class="k">print</span><span class="p">(</span><span class="n">matrix1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">matrix2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
             <span class="k">return</span> <span class="n">matrix1</span><span class="p">,</span><span class="n">matrix2</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="k">print</span><span class="p">(</span><span class="n">matrix1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
             <span class="k">return</span> <span class="n">matrix1</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we now have a 2-dimensional array for every star
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">babel_fish_dispenser</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
                                         <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5087, 3197, 2) (570, 3197, 2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># array on 2nd axis
</span><span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">x_train[-1] flux signal rolling avgs</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="c1"># plot arrays
</span><span class="n">rolling</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][:,</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">rolling</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rolling</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x_train[-1] flux signal rolling avgs

[-0.10910981 -0.10801068 -0.10926314 ... -0.18190533 -0.19232921
 -0.21176035] &lt;img src="/assets/images/starskope/output_48_2.png" width=400&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># viewed together...
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rolling</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_49_1.png" width="400" /></p>

<h2 id="model-1">Model</h2>

<h3 id="tactical-decisions"><strong>Tactical Decisions</strong></h3>

<p>Since I‚Äôm building the baseline model from scratch, a few considerations need to be made. While we can run a gridsearch (or randomizedsearchCV) to get the parameters for us, we still need to decide what type of model would be most ideal for this dataset, knowing what we know so far based on the work done so far. From there, we can go with best practices, assess the initial outcomes, and tune the hyperparameters with each iteration.</p>

<h3 id="cnn"><strong>CNN</strong></h3>
<p>The baseline will consist of a one-dimensional convolutional neural network (CNN). This is ideal for working with this particular dataset in which we will pass one row of the timeseries flux values as an array. This is very similar to how we would process image data (and that‚Äôs strategically useful if we want to develop the model in the future to handle Full-Frame Images from Tess, for instance, or spectographs of the flux frequences, for instance.</p>

<h3 id="1-layer-at-a-time"><strong>1-Layer at a time</strong></h3>
<p>We‚Äôll be using the Keras API which makes it easy to add in the layers one at a time. Each 1D convolutional layer corresponds to a local filter, and then a pooling layer reduces the data length by approximately a factor 4. At the end, there are two dense layers. Again, this is similar to the approach taken for a typical image classifier.</p>

<h3 id="activation-function"><strong>Activation Function</strong></h3>
<p>The RELU activation function is closest to how real neurons actually work and often produces the best results compared to the other options, so we‚Äôll at least start with this for the baseline.</p>

<h3 id="batch-normalization"><strong>Batch Normalization</strong></h3>
<p>Finally, the batch normalization layers are what help to speed up convergence.</p>

<h2 id="model-1"><code class="highlighter-rouge">Model 1</code></h2>

<p>We‚Äôll begin creating a baseline model with a lower than usual learning rate and then speed things up and fine-tune parameters for optimization in the next iterations. (The lower learning rate will help to ensure convergence.)</p>

<p>We‚Äôll increase the learning rate in Model2 iteration and also tune any other parameters as necessary. The first iteration uses the Adam optimizer, however, SGD is also a good option we could try here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5087, 3197, 2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5087, 1)
</code></pre></div></div>

<h2 id="build_cnn">build_cnn()</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">spacekit.builder</span> <span class="kn">import</span> <span class="n">Keras</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">builder</span><span class="p">.</span><span class="n">Keras</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">build_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
               <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
               <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
     <span class="s">"""
     Builds, compiles and fits a linear CNN using Keras API
     """</span>
     <span class="kn">import</span> <span class="nn">keras</span>
     <span class="kn">from</span> <span class="nn">keras.utils.np_utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
     <span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">optimizers</span>
     <span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
     <span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">MaxPool1D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> \
     <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">Activation</span>
     <span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
     <span class="kn">from</span> <span class="nn">keras.wrappers.scikit_learn</span> <span class="kn">import</span> <span class="n">KerasClassifier</span>
     <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

     <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">input_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
     <span class="k">if</span> <span class="n">kernel_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span>
     <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span>
     <span class="k">if</span> <span class="n">strides</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">strides</span> <span class="o">=</span> <span class="mi">4</span>
     <span class="k">if</span> <span class="n">learning_rate</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
     <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span>
     <span class="k">if</span> <span class="n">metrics</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"BUILDING MODEL..."</span><span class="p">)</span>
     <span class="n">model</span><span class="o">=</span><span class="n">Sequential</span><span class="p">()</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"LAYER 1"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
                      <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool1D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"LAYER 2"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool1D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"LAYER 3"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool1D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"LAYER 4"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool1D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"FULL CONNECTION"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>

     <span class="k">print</span><span class="p">(</span><span class="s">"ADDING COST FUNCTION"</span><span class="p">)</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

     <span class="c1">##### COMPILE #####
</span>     <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> 
                 <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>
     <span class="k">print</span><span class="p">(</span><span class="s">"COMPILED"</span><span class="p">)</span>  

     <span class="k">return</span> <span class="n">model</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m1</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">build_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> 
                     <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> 
                     <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILDING MODEL...
LAYER 1
LAYER 2
LAYER 3
LAYER 4
FULL CONNECTION
ADDING COST FUNCTION
COMPILED
</code></pre></div></div>

<h2 id="batch-generator">Batch Generator</h2>

<p>To correct for the extremely unbalanced dataset, we‚Äôll ensure that the network sees 50% of the positive sample over each batch. We will also apply augmentation by rotating each of the samples randomly each time, thus generating new data. This is similar to image classification when we rotate or shift the samples each time.</p>

<h3 id="fit_cnn">fit_cnn()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">fit_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                 <span class="n">verbose</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
       
         <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
         <span class="k">if</span> <span class="n">epochs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
         <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
         <span class="k">if</span> <span class="n">steps_per_epoch</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="n">batch_size</span><span class="p">)</span>
         <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

         <span class="k">print</span><span class="p">(</span><span class="s">"FITTING MODEL..."</span><span class="p">)</span>
        
         <span class="k">def</span> <span class="nf">batch_maker</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
                 <span class="s">"""
                 Gives equal number of positive and negative samples rotating randomly                
                 The output of the generator must be either
                 - a tuple `(inputs, targets)`
                 - a tuple `(inputs, targets, sample_weights)`.

                 This tuple (a single output of the generator) makes a single
                 batch. Therefore, all arrays in this tuple must have the same
                 length (equal to the size of this batch). Different batches may have 
                 different sizes. 

                 For example, the last batch of the epoch is commonly smaller than the others, 
                 if the size of the dataset is not divisible by the batch size.
                 The generator is expected to loop over its data indefinitely. 
                 An epoch finishes when `steps_per_epoch` batches have been seen by the model.
                
                 """</span>
                 <span class="kn">import</span> <span class="nn">numpy</span>
                 <span class="kn">import</span> <span class="nn">random</span>
                 <span class="c1"># hb: half-batch
</span>                 <span class="n">hb</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span>
                
                 <span class="c1"># Returns a new array of given shape and type, without initializing.
</span>                 <span class="c1"># x_train.shape = (5087, 3197, 2)
</span>                 <span class="n">xb</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">)</span>
               
                 <span class="c1">#y_train.shape = (5087, 1)
</span>                 <span class="n">yb</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">)</span>
                
                 <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                 <span class="n">neg</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                 <span class="c1"># rotating each of the samples randomly
</span>                 <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                     <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
                     <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">neg</span><span class="p">)</span>
                
                     <span class="n">xb</span><span class="p">[:</span><span class="n">hb</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">pos</span><span class="p">[:</span><span class="n">hb</span><span class="p">]]</span>
                     <span class="n">xb</span><span class="p">[</span><span class="n">hb</span><span class="p">:]</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">neg</span><span class="p">[</span><span class="n">hb</span><span class="p">:</span><span class="n">batch_size</span><span class="p">]]</span>
                     <span class="n">yb</span><span class="p">[:</span><span class="n">hb</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">pos</span><span class="p">[:</span><span class="n">hb</span><span class="p">]]</span>
                     <span class="n">yb</span><span class="p">[</span><span class="n">hb</span><span class="p">:]</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">neg</span><span class="p">[</span><span class="n">hb</span><span class="p">:</span><span class="n">batch_size</span><span class="p">]]</span>
                
                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                         <span class="n">size</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="n">xb</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                         <span class="n">xb</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">roll</span><span class="p">(</span><span class="n">xb</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">size</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
               
                     <span class="k">yield</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span>
        
         <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">batch_maker</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span>
                                         <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span> 
                                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> 
                                         <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"TRAINING COMPLETE"</span><span class="p">)</span>
         <span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>

         <span class="k">return</span> <span class="n">history</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">h1</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">fit_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span>
               <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
               <span class="n">steps_per_epoch</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FITTING MODEL...
Epoch 1/5
 - 26s - loss: 0.7978 - accuracy: 0.5044 - val_loss: 0.6152 - val_accuracy: 0.9351
Epoch 2/5
 - 24s - loss: 0.7549 - accuracy: 0.5117 - val_loss: 0.6112 - val_accuracy: 0.8439
Epoch 3/5
 - 26s - loss: 0.7197 - accuracy: 0.5319 - val_loss: 0.6259 - val_accuracy: 0.7386
Epoch 4/5
 - 26s - loss: 0.7358 - accuracy: 0.5063 - val_loss: 0.6466 - val_accuracy: 0.6474
Epoch 5/5
 - 23s - loss: 0.7300 - accuracy: 0.5142 - val_loss: 0.6549 - val_accuracy: 0.6193
TRAINING COMPLETE
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 3187, 8)           184       
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 797, 8)            0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 797, 8)            32        
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 787, 16)           1424      
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 197, 16)           0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 197, 16)           64        
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 187, 32)           5664      
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 47, 32)            0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 47, 32)            128       
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 37, 64)            22592     
_________________________________________________________________
max_pooling1d_4 (MaxPooling1 (None, 9, 64)             0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                36928     
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 65        
=================================================================
Total params: 71,241
Trainable params: 71,129
Non-trainable params: 112
_________________________________________________________________
</code></pre></div></div>

<h2 id="evaluate-m1">Evaluate (M1)</h2>

<p>Let‚Äôs assess the model thus far before tuning parameters. We‚Äôll create a few helper functions for calculating metrics and analyzing results visually.</p>

<h2 id="class-predictions-get_preds">Class Predictions: get_preds()</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

 <span class="k">def</span> <span class="nf">get_preds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">model</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
     <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">model</span><span class="o">=</span><span class="n">model</span>
     <span class="c1"># class predictions 
</span>     <span class="n">y_true</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
   
     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">flatten</span><span class="p">()</span> 
     <span class="n">preds</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_pred</span><span class="p">).</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
     <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
         <span class="k">print</span><span class="p">(</span><span class="s">f"y_pred:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">preds</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

     <span class="k">return</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">m1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y_pred:
 0    354
1    216
dtype: int64
</code></pre></div></div>

<h3 id="false---rates-training-fnfp">False -/+ Rates (Training): fnfp()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">fnfp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">model</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

     <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="p">)</span>

     <span class="n">pos_idx</span> <span class="o">=</span> <span class="n">y</span><span class="o">==</span><span class="mi">1</span>
     <span class="n">neg_idx</span> <span class="o">=</span> <span class="n">y</span><span class="o">==</span><span class="mi">0</span>

     <span class="c1">#tp = np.sum(y_pred[pos_idx]==1)/y_pred.shape[0]
</span>     <span class="n">fn</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">pos_idx</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">y_pred</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

     <span class="c1">#tn = np.sum(y_pred[neg_idx]==0)/y_pred.shape[0]
</span>     <span class="n">fp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">neg_idx</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">y_pred</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

     <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
         <span class="k">print</span><span class="p">(</span><span class="s">f"FN Rate (Training): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">fn</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s">%"</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">f"FP Rate (Training): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">fp</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s">%"</span><span class="p">)</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="k">print</span><span class="p">(</span><span class="s">f"FN Rate (Test): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">fn</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s">%"</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">f"FP Rate (Test): </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">fp</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s">%"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">computer</span><span class="p">.</span><span class="n">fnfp</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FN Rate (Training): 0.2556%
FP Rate (Training): 39.4339%
</code></pre></div></div>

<h3 id="false---rates-test">False -/+ Rates (Test)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">computer</span><span class="p">.</span><span class="n">fnfp</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m1</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FN Rate (Test): 0.5263%
FP Rate (Test): 37.5439%
</code></pre></div></div>

<h3 id="classification-report">Classification Report</h3>

<p>Sci-kit learn has a nice built-in method for evaluating our model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">recall_score</span>

<span class="n">report</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

         0.0       0.99      0.62      0.76       565
         1.0       0.01      0.40      0.02         5

    accuracy                           0.62       570
   macro avg       0.50      0.51      0.39       570
weighted avg       0.98      0.62      0.76       570
</code></pre></div></div>

<h4 id="fowlkes-mallows">Fowlkes-Mallows</h4>

<p>Fowlkes-Mallows is a good metric for imbalanced datasets, along with Jaccard which is similar to F1.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.7207089012303081
</code></pre></div></div>

<h3 id="interpret-scores">Interpret Scores</h3>
<p>With only 5 epochs, the model performed high in precision. However, because this such an imbalanced dataset, recall and F1 score are more critical metrics and these could definitely be improved. We‚Äôll tune some of the hyperparameters, specifically adjusting the learning rate and increasing the number of epochs up to 40.</p>

<h3 id="history-metrics-keras_history">History Metrics: keras_history()</h3>

<p>The baseline model is not meant to give us optimal results - the real test will be in our final model below. First let‚Äôs take a look at some of the visuals to understand what the scores really mean. This will help us decide how to proceed in tuning the model appropriately.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">keras_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">)):</span>
     <span class="s">"""
     side by side sublots of training val accuracy and loss (left and right respectively)
     """</span>
    
     <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
   
     <span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
     <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
     <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_accuracy'</span><span class="p">])</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Model Accuracy'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Accuracy'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'Train'</span><span class="p">,</span> <span class="s">'Test'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>

     <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Model Loss'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Loss'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'Train'</span><span class="p">,</span> <span class="s">'Test'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">computer</span><span class="p">.</span><span class="n">keras_history</span><span class="p">(</span><span class="n">h1</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_80_0.png" width="400" /></p>

<p>With only a few epochs, and a small learning rate, it‚Äôs obvious that our training parameters have a great deal of room for improvement. This is good - we will definitely need to adjust the learning rate. If that doesn‚Äôt go far enough in producing desired results, we can also try using a different optimizer such as SGD instead of Adam. For now let‚Äôs look at a few other key metrics.</p>

<h2 id="fusion-matrix">Fusion Matrix</h2>

<p>It‚Äôs like a confusion matrix, without the confusion‚Ä¶</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">fusion_matrix</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">'Fusion Matrix'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'Blues'</span><span class="p">,</span>
     <span class="n">print_raw</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span> 
     <span class="s">"""
     FUSION MATRIX!
     -------------
     It's like a confusion matrix...without the confusion.
   
     matrix: can pass in matrix or a tuple (ytrue,ypred) to create on the fly 
     classes: class names for target variables
     """</span>
     <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>                       
     <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span> <span class="c1">#ugh
</span>     <span class="kn">import</span> <span class="nn">itertools</span>
     <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
     <span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
     <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
   
     <span class="c1"># make matrix if tuple passed to matrix:
</span>     <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
         <span class="n">y_true</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
         <span class="n">y_pred</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">copy</span><span class="p">()</span>
        
         <span class="k">if</span> <span class="n">y_true</span><span class="p">.</span><span class="n">ndim</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
             <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
         <span class="k">if</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">ndim</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
             <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
         <span class="n">fusion</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="n">fusion</span> <span class="o">=</span> <span class="n">matrix</span>
    
     <span class="c1"># INTEGER LABELS
</span>     <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">classes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrix</span><span class="p">)))</span>

     <span class="c1">#NORMALIZING
</span>     <span class="c1"># Check if normalize is set to True
</span>     <span class="c1"># If so, normalize the raw fusion matrix before visualizing
</span>     <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
         <span class="n">fusion</span> <span class="o">=</span> <span class="n">fusion</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">fusion</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
         <span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.5</span>
         <span class="n">fmt</span><span class="o">=</span><span class="s">'.2f'</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="n">fmt</span><span class="o">=</span><span class="s">'d'</span>
         <span class="n">thresh</span> <span class="o">=</span> <span class="n">fusion</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    
     <span class="c1"># PLOT
</span>     <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">fusion</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s">'equal'</span><span class="p">)</span>
    
     <span class="c1"># Add title and axis labels 
</span>     <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span> 
     <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'TRUE'</span><span class="p">)</span> 
     <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'PRED'</span><span class="p">)</span>
    
     <span class="c1"># Add appropriate axis scales
</span>     <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
    
     <span class="c1"># Text formatting
</span>     <span class="n">fmt</span> <span class="o">=</span> <span class="s">'.2f'</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s">'d'</span>
     <span class="c1"># Add labels to each cell
</span>     <span class="c1">#thresh = fusion.max() / 2.
</span>     <span class="c1"># iterate thru matrix and append labels  
</span>     <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">fusion</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">fusion</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
         <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">fusion</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                 <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">'center'</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'white'</span> <span class="k">if</span> <span class="n">fusion</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s">'black'</span><span class="p">,</span>
                 <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
    
     <span class="c1"># Add a legend
</span>     <span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> 
     <span class="k">return</span> <span class="n">fusion</span><span class="p">,</span> <span class="n">fig</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m1_fusion</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">fusion_matrix</span><span class="p">(</span><span class="n">matrix</span><span class="o">=</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span> 
                          <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span><span class="s">'Planet'</span><span class="p">],</span> 
                                   <span class="n">title</span><span class="o">=</span><span class="s">'M1 Fusion Matrix'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_84_0.png" width="400" /></p>

<p>The baseline model only managed to correctly identify 2 planets in the test set, while missing the other 3. The model incorrectly classified 215 non-TCEs as planets.</p>

<h2 id="roc-auc-roc_plots">ROC AUC: roc_plots()</h2>

<p>Plot the ROC area under the curve</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="k">def</span> <span class="nf">roc_plots</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">model</span><span class="p">):</span>
     <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
     <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">accuracy_score</span>

     <span class="n">y_true</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
     <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

     <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> 

     <span class="c1"># Threshold Cutoff for predictions
</span>     <span class="n">crossover_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">fpr</span> <span class="o">&lt;=</span> <span class="n">tpr</span><span class="p">))</span>
     <span class="n">crossover_cutoff</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">crossover_index</span><span class="p">]</span>
     <span class="n">crossover_specificity</span> <span class="o">=</span> <span class="mf">1.</span><span class="o">-</span><span class="n">fpr</span><span class="p">[</span><span class="n">crossover_index</span><span class="p">]</span>

     <span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
     <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>

     <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="mf">1.</span><span class="o">-</span><span class="n">fpr</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Crossover at {0:.2f}, Specificity {1:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">crossover_cutoff</span><span class="p">,</span> <span class="n">crossover_specificity</span><span class="p">))</span>

     <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
     <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"ROC area under curve: {0:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)))</span>
     <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    
     <span class="n">roc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_hat</span><span class="p">)</span>

     <span class="k">return</span> <span class="n">roc</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m1_roc</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">roc_plots</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m1</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_88_0.png" width="400" /></p>

<h1 id="model-2"><code class="highlighter-rouge">Model 2</code></h1>

<p>Initial parameter tuning: increase learning rate to 3e-4 (0.0003), and increase epochs to 20.</p>

<h2 id="build-m2">Build M2</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#### MODEL 2 
# adjust learning rate to 3e-4
</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">build_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> 
                     <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> 
                     <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILDING MODEL...
LAYER 1
LAYER 2
LAYER 3
LAYER 4
FULL CONNECTION
ADDING COST FUNCTION
COMPILED
</code></pre></div></div>

<h2 id="fit-m2">Fit M2</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># increase number of epochs to 20
</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">fit_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span>
               <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
               <span class="n">steps_per_epoch</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FITTING MODEL...
Epoch 1/20
 - 22s - loss: 0.6945 - accuracy: 0.5827 - val_loss: 0.9014 - val_accuracy: 0.0193
Epoch 2/20
 - 24s - loss: 0.6220 - accuracy: 0.6493 - val_loss: 0.8088 - val_accuracy: 0.2842
Epoch 3/20
 - 26s - loss: 0.5791 - accuracy: 0.7033 - val_loss: 0.6019 - val_accuracy: 0.7175
Epoch 4/20
 - 27s - loss: 0.5302 - accuracy: 0.7276 - val_loss: 0.4064 - val_accuracy: 0.8509
Epoch 5/20
 - 29s - loss: 0.4857 - accuracy: 0.7715 - val_loss: 0.5536 - val_accuracy: 0.7140
Epoch 6/20
 - 25s - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.4794 - val_accuracy: 0.7316
Epoch 7/20
 - 24s - loss: 0.4059 - accuracy: 0.8220 - val_loss: 0.6372 - val_accuracy: 0.6351
Epoch 8/20
 - 29s - loss: 0.3419 - accuracy: 0.8488 - val_loss: 0.7515 - val_accuracy: 0.5930
Epoch 9/20
 - 28s - loss: 0.3195 - accuracy: 0.8665 - val_loss: 0.4455 - val_accuracy: 0.7667
Epoch 10/20
 - 27s - loss: 0.2705 - accuracy: 0.8971 - val_loss: 0.8245 - val_accuracy: 0.6070
Epoch 11/20
 - 28s - loss: 0.2380 - accuracy: 0.9066 - val_loss: 0.2590 - val_accuracy: 0.8789
Epoch 12/20
 - 23s - loss: 0.2056 - accuracy: 0.9274 - val_loss: 0.3441 - val_accuracy: 0.8684
Epoch 13/20
 - 41s - loss: 0.1805 - accuracy: 0.9280 - val_loss: 0.1826 - val_accuracy: 0.9298
Epoch 14/20
 - 30s - loss: 0.1878 - accuracy: 0.9397 - val_loss: 0.1023 - val_accuracy: 0.9684
Epoch 15/20
 - 23s - loss: 0.1755 - accuracy: 0.9451 - val_loss: 0.1844 - val_accuracy: 0.9404
Epoch 16/20
 - 23s - loss: 0.1658 - accuracy: 0.9400 - val_loss: 0.3103 - val_accuracy: 0.8719
Epoch 17/20
 - 23s - loss: 0.1483 - accuracy: 0.9501 - val_loss: 0.1477 - val_accuracy: 0.9526
Epoch 18/20
 - 23s - loss: 0.1628 - accuracy: 0.9470 - val_loss: 0.1443 - val_accuracy: 0.9439
Epoch 19/20
 - 29s - loss: 0.1118 - accuracy: 0.9631 - val_loss: 0.1330 - val_accuracy: 0.9614
Epoch 20/20
 - 31s - loss: 0.1173 - accuracy: 0.9580 - val_loss: 0.0629 - val_accuracy: 0.9842
TRAINING COMPLETE
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 output Shape              Param #   
=================================================================
conv1d_5 (Conv1D)            (None, 3187, 8)           184       
_________________________________________________________________
max_pooling1d_5 (MaxPooling1 (None, 797, 8)            0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 797, 8)            32        
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 787, 16)           1424      
_________________________________________________________________
max_pooling1d_6 (MaxPooling1 (None, 197, 16)           0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 197, 16)           64        
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 187, 32)           5664      
_________________________________________________________________
max_pooling1d_7 (MaxPooling1 (None, 47, 32)            0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 47, 32)            128       
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 37, 64)            22592     
_________________________________________________________________
max_pooling1d_8 (MaxPooling1 (None, 9, 64)             0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 576)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 576)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 64)                36928     
_________________________________________________________________
dropout_4 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 65        
=================================================================
Total params: 71,241
Trainable params: 71,129
Non-trainable params: 112
_________________________________________________________________
</code></pre></div></div>

<h2 id="evaluate-m2-compute">Evaluate M2: compute()</h2>

<p>The <code class="highlighter-rouge">compute</code> function combines all the functions used above for calculating the metrics into one shot:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fusion</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
             <span class="n">classes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">roc</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
     <span class="s">"""
     evaluates model predictions and stores the output in a dict
     returns `results`
     """</span>
     <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
     <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
     <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
     <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_score</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">fowlkes_mallows_score</span>

     <span class="c1"># initialize a spare improbability drive
</span>     <span class="n">res</span> <span class="o">=</span> <span class="p">{}</span>
     <span class="n">res</span><span class="p">[</span><span class="s">'model'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">name</span>
    
     <span class="c1"># class predictions 
</span>     <span class="k">if</span> <span class="n">preds</span><span class="p">:</span>
         <span class="n">y_true</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
         <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">flatten</span><span class="p">()</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'preds'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_pred</span><span class="p">]</span>

     <span class="k">if</span> <span class="n">summary</span><span class="p">:</span>
         <span class="n">summary</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'summary'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">summary</span>

     <span class="c1"># FUSION MATRIX
</span>     <span class="k">if</span> <span class="n">fusion</span><span class="p">:</span>
         <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
             <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'0'</span><span class="p">,</span><span class="s">'1'</span><span class="p">]</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="n">classes</span><span class="o">=</span><span class="n">classes</span>
         <span class="c1"># Plot fusion matrix
</span>         <span class="n">FM</span> <span class="o">=</span> <span class="n">fusion_matrix</span><span class="p">(</span><span class="n">matrix</span><span class="o">=</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span> 
                                     <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'FM'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FM</span>

     <span class="c1"># ROC Area Under Curve
</span>     <span class="k">if</span> <span class="n">roc</span><span class="p">:</span>
         <span class="n">ROC</span> <span class="o">=</span> <span class="n">roc_plots</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'ROC'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ROC</span>

     <span class="c1"># CLASSIFICATION REPORT
</span>     <span class="k">if</span> <span class="n">report</span><span class="p">:</span>
         <span class="n">num_dashes</span><span class="o">=</span><span class="mi">20</span>
         <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">'---'</span><span class="o">*</span><span class="n">num_dashes</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">CLASSIFICATION REPORT:'</span><span class="p">)</span>
         <span class="k">print</span><span class="p">(</span><span class="s">'---'</span><span class="o">*</span><span class="n">num_dashes</span><span class="p">)</span>
         <span class="c1"># generate report
</span>         <span class="n">report</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'report'</span><span class="p">]</span> <span class="o">=</span> <span class="n">report</span>
         <span class="k">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>


     <span class="c1"># save to dict:
</span>     <span class="n">res</span><span class="p">[</span><span class="s">'jaccard'</span><span class="p">]</span> <span class="o">=</span> <span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
     <span class="n">res</span><span class="p">[</span><span class="s">'fowlkes'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
     <span class="n">res</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
     <span class="n">res</span><span class="p">[</span><span class="s">'recall'</span><span class="p">]</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
     <span class="c1">#Plot Model Training Results (PLOT KERAS HISTORY)
</span>     <span class="k">if</span> <span class="n">hist</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">HIST</span> <span class="o">=</span> <span class="n">keras_history</span><span class="p">(</span><span class="n">hist</span><span class="p">)</span>
         <span class="n">res</span><span class="p">[</span><span class="s">'HIST'</span><span class="p">]</span> <span class="o">=</span> <span class="n">HIST</span>

     <span class="k">return</span> <span class="n">res</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_m2</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">m2</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="n">h2</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">summary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fusion</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span><span class="s">'Planet'</span><span class="p">],</span><span class="n">roc</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_96_0.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_96_1.png" width="400" /></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>------------------------------------------------------------
	CLASSIFICATION REPORT:
------------------------------------------------------------
              precision    recall  f1-score   support

         0.0       1.00      0.98      0.99       565
         1.0       0.36      1.00      0.53         5

    accuracy                           0.98       570
   macro avg       0.68      0.99      0.76       570
weighted avg       0.99      0.98      0.99       570
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_96_3.png" width="400" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We can retrieve a given metric from the computer's compute function 
# by accessing any of the given keys from the RES dictionary
</span>
<span class="c1"># res_m2.keys()
</span>
<span class="c1"># ['model']
# ['preds']
# ['summary']()
# ['FM'][0]
# ['FM'][1]
# ['ROC']
#print(res_m2['report'])
# ['jaccard']
</span> <span class="c1">#res_m2['fowlkes']
# ['accuracy']
# ['recall']
# ['HIST']
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_m2</span><span class="p">[</span><span class="s">'fowlkes'</span><span class="p">]</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9840290257993071
</code></pre></div></div>

<h1 id="model-3"><code class="highlighter-rouge">MODEL 3</code></h1>

<h2 id="build-m3">Build M3</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#### MODEL 3
# increase learning rate to 4e-3
</span>
<span class="n">m3</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">build_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> 
                     <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">4e-3</span><span class="p">,</span> 
                     <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILDING MODEL...
LAYER 1
LAYER 2
LAYER 3
LAYER 4
FULL CONNECTION
ADDING COST FUNCTION
COMPILED
</code></pre></div></div>

<h2 id="train-m3">Train M3</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># keep number of epochs at 20
</span>
<span class="n">h3</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">fit_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m3</span><span class="p">,</span>
               <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
               <span class="n">steps_per_epoch</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FITTING MODEL...
Epoch 1/20
 - 22s - loss: 0.6099 - accuracy: 0.6657 - val_loss: 0.0556 - val_accuracy: 0.9895
Epoch 2/20
 - 21s - loss: 0.4555 - accuracy: 0.7945 - val_loss: 0.2497 - val_accuracy: 0.9088
Epoch 3/20
 - 18s - loss: 0.3589 - accuracy: 0.8523 - val_loss: 0.3350 - val_accuracy: 0.8404
Epoch 4/20
 - 17s - loss: 0.2505 - accuracy: 0.8987 - val_loss: 0.3346 - val_accuracy: 0.8649
Epoch 5/20
 - 17s - loss: 0.3538 - accuracy: 0.8475 - val_loss: 0.2626 - val_accuracy: 0.8649
Epoch 6/20
 - 17s - loss: 0.2716 - accuracy: 0.8911 - val_loss: 0.0878 - val_accuracy: 0.9737
Epoch 7/20
 - 18s - loss: 0.2058 - accuracy: 0.9205 - val_loss: 0.1999 - val_accuracy: 0.9333
Epoch 8/20
 - 17s - loss: 0.1560 - accuracy: 0.9441 - val_loss: 0.3655 - val_accuracy: 0.8333
Epoch 9/20
 - 19s - loss: 0.1411 - accuracy: 0.9454 - val_loss: 0.2266 - val_accuracy: 0.8930
Epoch 10/20
 - 23s - loss: 0.1298 - accuracy: 0.9504 - val_loss: 0.1879 - val_accuracy: 0.9456
Epoch 11/20
 - 18s - loss: 0.1369 - accuracy: 0.9539 - val_loss: 0.0602 - val_accuracy: 0.9825
Epoch 12/20
 - 22s - loss: 0.1084 - accuracy: 0.9618 - val_loss: 0.0592 - val_accuracy: 0.9807
Epoch 13/20
 - 22s - loss: 0.0720 - accuracy: 0.9751 - val_loss: 0.0496 - val_accuracy: 0.9912
Epoch 14/20
 - 18s - loss: 0.0986 - accuracy: 0.9640 - val_loss: 0.0982 - val_accuracy: 0.9719
Epoch 15/20
 - 21s - loss: 0.1033 - accuracy: 0.9624 - val_loss: 0.0443 - val_accuracy: 0.9807
Epoch 16/20
 - 19s - loss: 0.1129 - accuracy: 0.9586 - val_loss: 0.3545 - val_accuracy: 0.8596
Epoch 17/20
 - 19s - loss: 0.1059 - accuracy: 0.9612 - val_loss: 0.4088 - val_accuracy: 0.8754
Epoch 18/20
 - 17s - loss: 0.1018 - accuracy: 0.9634 - val_loss: 0.1042 - val_accuracy: 0.9614
Epoch 19/20
 - 17s - loss: 0.0753 - accuracy: 0.9729 - val_loss: 0.0507 - val_accuracy: 0.9842
Epoch 20/20
 - 17s - loss: 0.0587 - accuracy: 0.9779 - val_loss: 0.0699 - val_accuracy: 0.9789
TRAINING COMPLETE
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 output Shape              Param #   
=================================================================
conv1d_9 (Conv1D)            (None, 3187, 8)           184       
_________________________________________________________________
max_pooling1d_9 (MaxPooling1 (None, 797, 8)            0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 797, 8)            32        
_________________________________________________________________
conv1d_10 (Conv1D)           (None, 787, 16)           1424      
_________________________________________________________________
max_pooling1d_10 (MaxPooling (None, 197, 16)           0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 197, 16)           64        
_________________________________________________________________
conv1d_11 (Conv1D)           (None, 187, 32)           5664      
_________________________________________________________________
max_pooling1d_11 (MaxPooling (None, 47, 32)            0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 47, 32)            128       
_________________________________________________________________
conv1d_12 (Conv1D)           (None, 37, 64)            22592     
_________________________________________________________________
max_pooling1d_12 (MaxPooling (None, 9, 64)             0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 576)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 576)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 64)                36928     
_________________________________________________________________
dropout_6 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_8 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 65        
=================================================================
Total params: 71,241
Trainable params: 71,129
Non-trainable params: 112
_________________________________________________________________
</code></pre></div></div>

<h2 id="evaluate-m3">Evaluate M3</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_m3</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">m3</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="n">h3</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">summary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fusion</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span><span class="s">'Planet'</span><span class="p">],</span><span class="n">roc</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_105_0.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_105_1.png" width="400" /></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>------------------------------------------------------------
	CLASSIFICATION REPORT:
------------------------------------------------------------
              precision    recall  f1-score   support

         0.0       1.00      0.98      0.99       565
         1.0       0.29      1.00      0.45         5

    accuracy                           0.98       570
   macro avg       0.65      0.99      0.72       570
weighted avg       0.99      0.98      0.98       570
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_105_3.png" width="400" /></p>

<p>It appears that increasing the learning rate did not help to improve the model‚Äôs performance. While it still identified all 5 planets, it misclassified 4 non-planets as planets, two more than model 2. Let‚Äôs see if we can decrease the False Positive Rate, while Maintaining the False Negative Rate at zero. We‚Äôll go back to Model 2‚Äôs original learning rate of 3e-4, this time increasing the number of epochs instead.</p>

<h1 id="model-4"><code class="highlighter-rouge">MODEL 4</code></h1>

<h2 id="build-m4">Build M4</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#### MODEL 4
# decrease learning rate back to 3e-4
</span>
<span class="n">m4</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">build_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> 
                     <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> 
                     <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> 
                     <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILDING MODEL...
LAYER 1
LAYER 2
LAYER 3
LAYER 4
FULL CONNECTION
ADDING COST FUNCTION
COMPILED
</code></pre></div></div>

<h2 id="fit-m4">Fit M4</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># increase number of epochs to 33
</span>
<span class="n">h4</span> <span class="o">=</span> <span class="n">K</span><span class="p">.</span><span class="n">fit_cnn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">m4</span><span class="p">,</span>
               <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> 
               <span class="n">steps_per_epoch</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FITTING MODEL...
Epoch 1/33
 - 17s - loss: 0.6739 - accuracy: 0.5931 - val_loss: 0.8185 - val_accuracy: 0.1211
Epoch 2/33
 - 18s - loss: 0.6006 - accuracy: 0.6777 - val_loss: 0.6971 - val_accuracy: 0.4772
Epoch 3/33
 - 20s - loss: 0.5806 - accuracy: 0.6989 - val_loss: 0.4942 - val_accuracy: 0.8281
Epoch 4/33
 - 19s - loss: 0.5300 - accuracy: 0.7412 - val_loss: 0.4063 - val_accuracy: 0.8439
Epoch 5/33
 - 18s - loss: 0.4974 - accuracy: 0.7620 - val_loss: 0.4653 - val_accuracy: 0.7614
Epoch 6/33
 - 18s - loss: 0.4563 - accuracy: 0.7907 - val_loss: 0.7816 - val_accuracy: 0.5632
Epoch 7/33
 - 18s - loss: 0.4144 - accuracy: 0.8239 - val_loss: 0.5558 - val_accuracy: 0.7140
Epoch 8/33
 - 18s - loss: 0.3503 - accuracy: 0.8561 - val_loss: 0.1770 - val_accuracy: 0.9228
Epoch 9/33
 - 19s - loss: 0.3230 - accuracy: 0.8636 - val_loss: 0.2454 - val_accuracy: 0.8807
Epoch 10/33
 - 18s - loss: 0.2673 - accuracy: 0.8984 - val_loss: 0.9147 - val_accuracy: 0.6526
Epoch 11/33
 - 18s - loss: 0.2434 - accuracy: 0.9091 - val_loss: 0.8955 - val_accuracy: 0.6228
Epoch 12/33
 - 18s - loss: 0.2401 - accuracy: 0.9119 - val_loss: 0.5549 - val_accuracy: 0.7474
Epoch 13/33
 - 17s - loss: 0.1985 - accuracy: 0.9227 - val_loss: 0.2674 - val_accuracy: 0.8860
Epoch 14/33
 - 19s - loss: 0.2019 - accuracy: 0.9255 - val_loss: 0.1316 - val_accuracy: 0.9439
Epoch 15/33
 - 17s - loss: 0.1642 - accuracy: 0.9416 - val_loss: 0.0758 - val_accuracy: 0.9702
Epoch 16/33
 - 17s - loss: 0.1833 - accuracy: 0.9331 - val_loss: 0.0558 - val_accuracy: 0.9860
Epoch 17/33
 - 17s - loss: 0.1506 - accuracy: 0.9476 - val_loss: 0.2535 - val_accuracy: 0.9035
Epoch 18/33
 - 17s - loss: 0.1445 - accuracy: 0.9501 - val_loss: 0.1732 - val_accuracy: 0.9368
Epoch 19/33
 - 17s - loss: 0.1302 - accuracy: 0.9558 - val_loss: 0.1816 - val_accuracy: 0.9474
Epoch 20/33
 - 17s - loss: 0.1176 - accuracy: 0.9586 - val_loss: 0.0928 - val_accuracy: 0.9737
Epoch 21/33
 - 17s - loss: 0.1099 - accuracy: 0.9653 - val_loss: 0.0820 - val_accuracy: 0.9754
Epoch 22/33
 - 17s - loss: 0.1263 - accuracy: 0.9552 - val_loss: 0.0566 - val_accuracy: 0.9825
Epoch 23/33
 - 18s - loss: 0.1067 - accuracy: 0.9628 - val_loss: 0.0553 - val_accuracy: 0.9877
Epoch 24/33
 - 19s - loss: 0.1192 - accuracy: 0.9605 - val_loss: 0.0911 - val_accuracy: 0.9649
Epoch 25/33
 - 17s - loss: 0.0929 - accuracy: 0.9675 - val_loss: 0.1150 - val_accuracy: 0.9632
Epoch 26/33
 - 18s - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.0455 - val_accuracy: 0.9895
Epoch 27/33
 - 19s - loss: 0.0942 - accuracy: 0.9672 - val_loss: 0.0470 - val_accuracy: 0.9877
Epoch 28/33
 - 18s - loss: 0.0875 - accuracy: 0.9700 - val_loss: 0.0856 - val_accuracy: 0.9737
Epoch 29/33
 - 18s - loss: 0.0784 - accuracy: 0.9713 - val_loss: 0.0888 - val_accuracy: 0.9754
Epoch 30/33
 - 18s - loss: 0.0860 - accuracy: 0.9706 - val_loss: 0.0523 - val_accuracy: 0.9895
Epoch 31/33
 - 18s - loss: 0.0967 - accuracy: 0.9694 - val_loss: 0.1047 - val_accuracy: 0.9649
Epoch 32/33
 - 18s - loss: 0.0722 - accuracy: 0.9757 - val_loss: 0.0571 - val_accuracy: 0.9825
Epoch 33/33
 - 17s - loss: 0.0965 - accuracy: 0.9678 - val_loss: 0.1138 - val_accuracy: 0.9596
TRAINING COMPLETE
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 output Shape              Param #   
=================================================================
conv1d_17 (Conv1D)           (None, 3187, 8)           184       
_________________________________________________________________
max_pooling1d_17 (MaxPooling (None, 797, 8)            0         
_________________________________________________________________
batch_normalization_13 (Batc (None, 797, 8)            32        
_________________________________________________________________
conv1d_18 (Conv1D)           (None, 787, 16)           1424      
_________________________________________________________________
max_pooling1d_18 (MaxPooling (None, 197, 16)           0         
_________________________________________________________________
batch_normalization_14 (Batc (None, 197, 16)           64        
_________________________________________________________________
conv1d_19 (Conv1D)           (None, 187, 32)           5664      
_________________________________________________________________
max_pooling1d_19 (MaxPooling (None, 47, 32)            0         
_________________________________________________________________
batch_normalization_15 (Batc (None, 47, 32)            128       
_________________________________________________________________
conv1d_20 (Conv1D)           (None, 37, 64)            22592     
_________________________________________________________________
max_pooling1d_20 (MaxPooling (None, 9, 64)             0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 576)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 576)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 64)                36928     
_________________________________________________________________
dropout_10 (Dropout)         (None, 64)                0         
_________________________________________________________________
dense_14 (Dense)             (None, 64)                4160      
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 65        
=================================================================
Total params: 71,241
Trainable params: 71,129
Non-trainable params: 112
_________________________________________________________________
</code></pre></div></div>

<h2 id="evaluate-m4">Evaluate M4</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_m4</span> <span class="o">=</span> <span class="n">computer</span><span class="p">.</span><span class="n">compute</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">m4</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="n">h4</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">summary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fusion</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
               <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'No Planet'</span><span class="p">,</span><span class="s">'Planet'</span><span class="p">],</span><span class="n">roc</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_113_0.png" width="400" /></p>

<p><img src="/assets/images/starskope/output_113_1.png" width="400" /></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>------------------------------------------------------------
	CLASSIFICATION REPORT:
------------------------------------------------------------
              precision    recall  f1-score   support

         0.0       1.00      0.96      0.98       565
         1.0       0.18      1.00      0.30         5

    accuracy                           0.96       570
   macro avg       0.59      0.98      0.64       570
weighted avg       0.99      0.96      0.97       570
</code></pre></div></div>

<p><img src="/assets/images/starskope/output_113_3.png" width="400" /></p>

<h1 id="interpret-results">Interpret Results</h1>

<h2 id="conclusion-1">Conclusion</h2>

<p>Above, we were able to identify with 99% accuracy 5 of 5 stars with an orbiting exoplanet (or exoplanets). The best model (MODEL 2) incorrectly predicted just 2 False Positives, with ZERO false negatives.</p>

<h2 id="save-weights-model-2">Save Weights (Model 2)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># # %mkdir models
# m2.save_weights('models/k2_cnn1d.h5')
</span></code></pre></div></div>

<h1 id="recommendations-1">Recommendations</h1>

<p>While it is possible to create a near-perfect classification model for detecting exoplanets using the raw flux values of an imbalanced data set, the model would benefit from further validation using additional data from either K2 or another telescope such as TESS. One issue with this model is that it doesn‚Äôt reveal how it makes the decision on each prediction, an insight that would be extremely useful for astrophysicists and for developing and improving the model itself. A better, more robust and useful model, therefore, would be one which gives such insight without sacrificing accuracy or recall.</p>

<p>My recommendations are the following:</p>

<ol>
  <li>
    <p>Use datasets from the MAST website (via API) to incorporate other calculations of the star‚Äôs properties as features to be used for classification algorithms. Furthermore, attempt other types of transformations and normalizations on the data before running the model - for instance, apply Fourier transform and phase folding.</p>
  </li>
  <li>
    <p>Combine data from multiple campaigns and perhaps even multiple telescopes (for instance, matching sky coordinates and time intervals between K2, Kepler, and TESS for a batch of stars that have overlapping observations - this would be critical for finding transit periods that are longer than the campaigns of a single telecope‚Äôs observation period).</p>
  </li>
  <li>
    <p>Explore using computer vision on not only the Full Frame images we can collect from telescopes like TESS, but also on spectographs of the flux values themselves. The beauty of machine learning is our ability to rely on the computer to pick up very small nuances in differences that we ourselves cannot see with our own eyes.</p>
  </li>
  <li>
    <p>Explore using autoencoded machine learning algorithms with Restricted Boltzmann Machines - this type of model has proven to be incredibly effective in the image analysis of handwriting as we‚Äôve seen applied the MNIST dataset - let‚Äôs find out if the same is true for images of stars, be they the Full Frame Images or spectographs.</p>
  </li>
</ol>

<h1 id="future-work-1">Future Work</h1>

<p>To continue this project, I‚Äôll take another approach for detecting exoplanets using computer vision to analyze images of spectographs of this same star flux data set. In part II <a href="/datascience/2020/05/06/starskope-2-spectrograph-image-classification.html">starsk√∏pe-2</a> I use Restricted Boltzmann Machines on Fourier-transformed spectograph images of the Flux data for K2. These are then stacked on top of each other as layers in a Deep Boltzmann Machine neural network. In part III <a href="/datascience/2020/06/01/starskope-3-scraping-mast-api.html">starsk√∏pe-3</a> I will apply a similar technique using data from TESS.</p>

<p>For triage/vetting purposes, this model could be useful for scientists. However, I would like to extend the model‚Äôs capability using a multiclassification algorithm that can tell us not only if there is a transiting body, but how many, as well as additional information about the star‚Äôs properties. The latter could be done by training another model on stellar parameters, and then stacking the two together into one neural network.</p>
:ET