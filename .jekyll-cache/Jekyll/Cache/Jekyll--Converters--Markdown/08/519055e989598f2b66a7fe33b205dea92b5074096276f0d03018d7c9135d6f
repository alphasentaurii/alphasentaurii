I"…<p>The vision for <code class="highlighter-rouge">StarskÃ¸pe</code> : cyberoptic artificial telescope is to aggregate large datasets from multiple missions in order to give us a more accurate, more detailed picture of the stars and planets than what we have available to us in the limited view of a single picture from a single telescope at a single point in time.</p>

<h2 id="scraping-the-mast-api-via-amazon-web-services-aws">Scraping the MAST API via Amazon Web Services (AWS)</h2>

<ol>
  <li>
    <p>Use datasets from the MAST website (via API) to incorporate other calculations of the starâ€™s properties as features to be used for classification algorithms. Furthermore, attempt other types of transformations and normalizations on the data before running the model - for instance, apply a Fourier transform.</p>
  </li>
  <li>
    <p>Combine data from multiple campaigns and perhaps even multiple telescopes (for instance, matching sky coordinates and time intervals between K2, Kepler, and TESS for a batch of stars that have overlapping observations - this would be critical for finding transit periods that are longer than the campaigns of a single telecopeâ€™s observation period).</p>
  </li>
  <li>
    <p>Explore using computer vision on not only the Full Frame images we can collect from telescopes like TESS, but also on spectographs of the flux values themselves. The beauty of machine learning is our ability to rely on the computer to pick up very small nuances in differences that we ourselves cannot see with our own eyes.</p>
  </li>
  <li>
    <p>Explore using autoencoded machine learning algorithms with Restricted Boltzmann Machines - this type of model has proven to be incredibly effective in the image analysis of handwriting as weâ€™ve seen applied the MNIST dataset - letâ€™s find out if the same is true for images of stars, be they the Full Frame Images or spectographs.</p>
  </li>
</ol>

:ET